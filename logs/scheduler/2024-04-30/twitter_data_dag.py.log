[2024-04-30T06:38:29.826+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:38:29.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:38:29.832+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:38:29.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:38:35.361+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:38:35.609+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:38:35.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:38:35.634+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:38:35.634+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-27 00:00:00+00:00, run_after=2024-04-28 00:00:00+00:00
[2024-04-30T06:38:35.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 5.841 seconds
[2024-04-30T06:39:05.957+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:39:05.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:39:05.967+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:39:05.966+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:39:15.275+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:39:15.342+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:39:15.340+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:39:15.426+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:39:15.424+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:39:15.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 9.545 seconds
[2024-04-30T06:39:45.802+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:39:45.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:39:45.807+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:39:45.807+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:39:48.812+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:39:48.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:39:48.835+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:39:48.859+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:39:48.858+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:39:48.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.091 seconds
[2024-04-30T06:40:19.143+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:19.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:40:19.147+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:19.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:22.356+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:22.396+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:22.395+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:40:22.431+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:22.431+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:40:22.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.322 seconds
[2024-04-30T06:40:30.564+0000] {processor.py:161} INFO - Started process (PID=469) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:30.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:40:30.569+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:30.568+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:33.007+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:33.135+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:33.134+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:40:33.155+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:33.154+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:40:33.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.623 seconds
[2024-04-30T06:40:43.069+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:43.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:40:43.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:43.072+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:45.404+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:40:45.415+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:45.415+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:40:45.438+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:40:45.438+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:40:45.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.397 seconds
[2024-04-30T06:41:15.699+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:41:15.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:41:15.702+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:41:15.702+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:41:30.033+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:41:31.365+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:41:31.364+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:41:31.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:41:31.592+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:41:31.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 16.049 seconds
[2024-04-30T06:42:10.956+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:42:13.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:42:13.261+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:13.246+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:42:30.141+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:42:30.245+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:30.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:42:30.298+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:30.298+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:42:30.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 21.397 seconds
[2024-04-30T06:42:40.319+0000] {processor.py:161} INFO - Started process (PID=1177) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:42:40.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:42:40.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:40.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:42:45.369+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:42:45.411+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.410+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:07:49.596371+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.442+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.442+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090749, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.470+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:07:49.596371+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.475+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.475+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-27T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.492+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.492+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T000000, start_date=20240430T064149, end_date=20240430T064245
[2024-04-30T06:42:45.497+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-27T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.501+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.500+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:02:15.515320+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.513+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.513+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090215, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.518+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:02:15.515320+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.523+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.523+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T08:55:08.565808+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.533+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.533+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T085508, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.538+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T08:55:08.565808+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.543+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.543+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:09:47.810643+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.556+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.555+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090947, start_date=20240430T064149, end_date=20240430T064245
[2024-04-30T06:42:45.561+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:09:47.810643+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.565+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.565+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.579+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.579+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T064147, end_date=20240430T064245
[2024-04-30T06:42:45.584+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.590+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.590+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-26T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.604+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.604+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240426T000000, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.610+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-26T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.613+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.613+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:07:49.596371+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.625+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.625+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090749, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.634+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:07:49.596371+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.638+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.637+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-27T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.651+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.651+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T000000, start_date=20240430T064149, end_date=20240430T064245
[2024-04-30T06:42:45.657+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-27T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.661+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.660+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:02:15.515320+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.672+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.672+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090215, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.676+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:02:15.515320+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.680+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.680+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T08:55:08.565808+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.693+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.692+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T085508, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.697+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T08:55:08.565808+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.701+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.700+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:09:47.810643+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.712+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.712+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090947, start_date=20240430T064149, end_date=20240430T064245
[2024-04-30T06:42:45.716+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:09:47.810643+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.721+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.721+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.732+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.732+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T064147, end_date=20240430T064245
[2024-04-30T06:42:45.737+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.741+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.741+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-26T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.753+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.753+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240426T000000, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.761+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-26T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.765+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.765+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:07:49.596371+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:42:45.776+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.775+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090749, start_date=20240430T064148, end_date=20240430T064245
[2024-04-30T06:42:45.780+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:07:49.596371+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:42:45.810+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.809+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:42:45.845+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:42:45.844+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:42:45.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 5.573 seconds
[2024-04-30T06:43:16.169+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:43:16.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:43:16.173+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:16.173+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:43:18.708+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:43:18.736+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.735+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-27T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:43:18.752+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.752+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T000000, start_date=20240430T064149, end_date=20240430T064318
[2024-04-30T06:43:18.761+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-27T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:43:18.764+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.764+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:02:15.515320+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:43:18.770+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.770+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090215, start_date=20240430T064148, end_date=20240430T064318
[2024-04-30T06:43:18.774+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:02:15.515320+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:43:18.777+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.776+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T08:55:08.565808+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:43:18.785+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.785+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T085508, start_date=20240430T064148, end_date=20240430T064318
[2024-04-30T06:43:18.789+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T08:55:08.565808+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:43:18.792+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.791+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:09:47.810643+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:43:18.799+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.799+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090947, start_date=20240430T064149, end_date=20240430T064318
[2024-04-30T06:43:18.802+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:09:47.810643+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:43:18.804+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.804+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:43:18.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.811+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T064147, end_date=20240430T064318
[2024-04-30T06:43:18.814+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:43:18.816+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.816+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-26T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:43:18.823+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.823+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240426T000000, start_date=20240430T064148, end_date=20240430T064318
[2024-04-30T06:43:18.827+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-26T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:43:18.847+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.846+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:43:18.865+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:18.864+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:43:18.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.720 seconds
[2024-04-30T06:43:49.274+0000] {processor.py:161} INFO - Started process (PID=1257) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:43:49.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:43:49.278+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:49.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:43:51.769+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:43:51.794+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:51.794+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:43:51.821+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:43:51.821+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:43:51.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.576 seconds
[2024-04-30T06:44:22.087+0000] {processor.py:161} INFO - Started process (PID=1303) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:44:22.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:44:22.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:44:22.090+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:44:24.549+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:44:24.575+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:44:24.574+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:44:24.603+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:44:24.603+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:44:24.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.546 seconds
[2024-04-30T06:44:54.972+0000] {processor.py:161} INFO - Started process (PID=1367) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:44:54.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:44:54.978+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:44:54.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:45:03.204+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:45:03.264+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:45:03.263+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:45:03.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:45:03.333+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:45:03.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 8.442 seconds
[2024-04-30T06:45:34.581+0000] {processor.py:161} INFO - Started process (PID=1838) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:45:34.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:45:34.598+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:45:34.591+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:45:49.010+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:45:49.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:45:49.081+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:45:49.130+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:45:49.130+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:45:49.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 14.611 seconds
[2024-04-30T06:45:57.032+0000] {processor.py:161} INFO - Started process (PID=1857) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:45:57.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:45:57.185+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:45:57.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:46:05.408+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:46:05.456+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.455+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-27T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.513+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.512+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T000000, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.551+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-27T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.558+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.558+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:09:47.810643+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.573+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.573+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090947, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.585+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:09:47.810643+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.591+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.590+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:01:13.789783+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.609+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.609+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090113, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.619+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:01:13.789783+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.629+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.628+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T08:51:15.232230+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.657+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.656+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T085115, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.663+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T08:51:15.232230+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.670+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.670+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-28T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.710+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.710+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240428T000000, start_date=20240430T064506, end_date=20240430T064605
[2024-04-30T06:46:05.719+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-28T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.723+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.723+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.745+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.745+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.750+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.758+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.757+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-26T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.782+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.782+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240426T000000, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.794+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-26T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.806+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.806+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-27T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.827+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.827+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T000000, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.832+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-27T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.836+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:09:47.810643+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.848+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.848+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090947, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.855+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:09:47.810643+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.859+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.859+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:01:13.789783+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.872+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.872+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090113, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.878+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:01:13.789783+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.885+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.885+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T08:51:15.232230+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.899+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.899+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T085115, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.912+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T08:51:15.232230+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.920+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.920+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-28T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.950+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.950+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240428T000000, start_date=20240430T064506, end_date=20240430T064605
[2024-04-30T06:46:05.958+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-28T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:05.967+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.966+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:05.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:05.983+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T064507, end_date=20240430T064605
[2024-04-30T06:46:05.989+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:06.000+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:06.000+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-26T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:06.022+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:06.021+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240426T000000, start_date=20240430T064507, end_date=20240430T064606
[2024-04-30T06:46:06.029+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-26T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:06.037+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:06.036+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-27T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:06.059+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:06.056+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T000000, start_date=20240430T064507, end_date=20240430T064606
[2024-04-30T06:46:06.068+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-27T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:06.106+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:06.105+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:46:06.141+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:06.140+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:46:06.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 9.582 seconds
[2024-04-30T06:46:36.905+0000] {processor.py:161} INFO - Started process (PID=1904) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:46:36.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:46:36.910+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:36.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:46:43.140+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:46:43.190+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.189+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:09:47.810643+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:43.261+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.261+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090947, start_date=20240430T064507, end_date=20240430T064643
[2024-04-30T06:46:43.281+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:09:47.810643+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:43.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.289+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:01:13.789783+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:43.311+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.310+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090113, start_date=20240430T064507, end_date=20240430T064643
[2024-04-30T06:46:43.317+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:01:13.789783+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:43.323+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.323+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T08:51:15.232230+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:43.350+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.349+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T085115, start_date=20240430T064507, end_date=20240430T064643
[2024-04-30T06:46:43.355+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T08:51:15.232230+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:43.360+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.359+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-28T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:43.377+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.377+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240428T000000, start_date=20240430T064506, end_date=20240430T064643
[2024-04-30T06:46:43.388+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-28T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:43.392+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.392+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:43.407+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.407+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T064507, end_date=20240430T064643
[2024-04-30T06:46:43.415+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:43.429+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.428+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-26T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:46:43.447+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.446+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240426T000000, start_date=20240430T064507, end_date=20240430T064643
[2024-04-30T06:46:43.452+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-26T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:46:43.485+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.484+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:46:43.525+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:46:43.525+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:46:43.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 6.687 seconds
[2024-04-30T06:47:14.146+0000] {processor.py:161} INFO - Started process (PID=2014) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:47:14.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:47:14.149+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:47:14.149+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:47:16.903+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:47:16.929+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:47:16.928+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:47:16.951+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:47:16.951+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:47:16.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.839 seconds
[2024-04-30T06:47:47.063+0000] {processor.py:161} INFO - Started process (PID=2054) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:47:47.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:47:47.066+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:47:47.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:47:50.010+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:47:50.035+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:47:50.035+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:47:50.058+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:47:50.058+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:47:50.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.025 seconds
[2024-04-30T06:48:20.330+0000] {processor.py:161} INFO - Started process (PID=2094) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:48:20.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:48:20.333+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:48:20.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:48:23.124+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:48:23.149+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:48:23.149+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:48:23.175+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:48:23.174+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:48:23.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.876 seconds
[2024-04-30T06:48:53.594+0000] {processor.py:161} INFO - Started process (PID=2134) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:48:53.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:48:53.599+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:48:53.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:48:56.349+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:48:56.373+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:48:56.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:48:56.399+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:48:56.399+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:48:56.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.834 seconds
[2024-04-30T06:49:26.679+0000] {processor.py:161} INFO - Started process (PID=2174) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:49:26.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:49:26.682+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:49:26.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:49:29.590+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:49:29.618+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:49:29.617+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:49:29.640+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:49:29.640+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:49:29.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.989 seconds
[2024-04-30T06:49:59.895+0000] {processor.py:161} INFO - Started process (PID=2214) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:49:59.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:49:59.900+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:49:59.899+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:50:03.899+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:50:03.977+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:50:03.976+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:50:04.079+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:50:04.078+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:50:04.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 4.329 seconds
[2024-04-30T06:50:41.357+0000] {processor.py:161} INFO - Started process (PID=2648) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:50:41.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:50:41.490+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:50:41.471+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:51:32.961+0000] {processor.py:161} INFO - Started process (PID=2800) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:51:33.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:51:33.385+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:33.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:51:50.073+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:51:50.109+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.108+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:07:49.596371+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.145+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.145+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090749, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.168+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:07:49.596371+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.177+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.177+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.194+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.194+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.201+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.206+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.206+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:02:15.515320+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.216+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.216+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090215, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.220+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:02:15.515320+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.224+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.223+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-30T06:44:48.066541+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.233+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.233+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240430T064448, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.238+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-30T06:44:48.066541+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.242+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.242+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:07:49.596371+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.252+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.252+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090749, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.257+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:07:49.596371+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.260+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.260+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.271+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.271+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.274+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.277+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.277+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:02:15.515320+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.286+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.286+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090215, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.290+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:02:15.515320+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.293+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.292+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-30T06:44:48.066541+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:51:50.302+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.302+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240430T064448, start_date=20240430T065024, end_date=20240430T065150
[2024-04-30T06:51:50.306+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-30T06:44:48.066541+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:51:50.669+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.669+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:51:50.699+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:50.698+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:51:50.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 17.418 seconds
[2024-04-30T06:51:54.976+0000] {processor.py:161} INFO - Started process (PID=2824) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:51:54.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:51:54.982+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:51:54.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:52:00.244+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:52:00.280+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.279+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:07:49.596371+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.303+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.303+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090749, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.315+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:07:49.596371+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.319+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.319+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.329+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.329+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.334+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.338+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.337+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:02:15.515320+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.347+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090215, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.351+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:02:15.515320+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.354+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.354+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-30T06:44:48.066541+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.363+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.363+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240430T064448, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.367+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-30T06:44:48.066541+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.370+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.370+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:07:49.596371+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.379+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.379+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090749, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.518+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:07:49.596371+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.522+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.522+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-29T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.535+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.535+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240429T000000, start_date=20240430T065027, end_date=20240430T065200
[2024-04-30T06:52:00.542+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-29T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.547+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.547+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:08:30.690537+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.561+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.561+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090830, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.567+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:08:30.690537+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.573+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.572+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:02:15.515320+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.594+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.593+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090215, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.598+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:02:15.515320+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.602+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.602+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-30T06:44:48.066541+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.613+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.612+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240430T064448, start_date=20240430T065024, end_date=20240430T065200
[2024-04-30T06:52:00.618+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-30T06:44:48.066541+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.622+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.621+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'scheduled__2024-04-29T00:00:00+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:52:00.634+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.634+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240429T000000, start_date=20240430T065027, end_date=20240430T065200
[2024-04-30T06:52:00.639+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script scheduled__2024-04-29T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:52:00.657+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.656+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:52:00.689+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:00.688+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:52:00.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 5.748 seconds
[2024-04-30T06:52:30.926+0000] {processor.py:161} INFO - Started process (PID=2864) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:52:30.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:52:30.929+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:30.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:52:36.538+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:52:36.579+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:36.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:52:36.630+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:52:36.630+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:52:36.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 5.868 seconds
[2024-04-30T06:53:06.955+0000] {processor.py:161} INFO - Started process (PID=2980) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:53:06.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:53:06.958+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:53:06.957+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:53:09.375+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:53:09.400+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:53:09.399+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:53:09.421+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:53:09.421+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:53:09.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.492 seconds
[2024-04-30T06:53:39.792+0000] {processor.py:161} INFO - Started process (PID=3020) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:53:39.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:53:39.795+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:53:39.794+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:53:42.585+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:53:42.606+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:53:42.606+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:53:42.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:53:42.628+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:53:42.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.864 seconds
[2024-04-30T06:54:13.246+0000] {processor.py:161} INFO - Started process (PID=3060) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:54:13.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:54:13.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:54:13.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:54:15.668+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:54:15.693+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:54:15.692+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:54:15.716+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:54:15.715+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:54:15.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.497 seconds
[2024-04-30T06:54:45.978+0000] {processor.py:161} INFO - Started process (PID=3100) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:54:45.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:54:45.980+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:54:45.980+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:54:48.340+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:54:48.364+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:54:48.364+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:54:48.385+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:54:48.385+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:54:48.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.434 seconds
[2024-04-30T06:55:18.639+0000] {processor.py:161} INFO - Started process (PID=3140) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:55:18.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:55:18.641+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:18.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:55:20.990+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:55:21.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:21.012+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:55:21.033+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:21.033+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:55:21.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.419 seconds
[2024-04-30T06:55:48.490+0000] {processor.py:161} INFO - Started process (PID=3194) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:55:48.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:55:48.493+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:48.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:55:52.102+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:55:52.164+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:52.159+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T08:51:15.232230+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:55:52.206+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:52.206+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T085115, start_date=20240430T065024, end_date=20240430T065552
[2024-04-30T06:55:52.229+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T08:51:15.232230+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:55:52.278+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:52.277+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:55:52.322+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:52.322+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:55:52.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.882 seconds
[2024-04-30T06:55:58.650+0000] {processor.py:161} INFO - Started process (PID=3247) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:55:58.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:55:58.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:55:58.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:56:01.799+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:56:01.822+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:01.821+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:01:13.789783+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:56:01.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:01.836+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090113, start_date=20240430T065024, end_date=20240430T065601
[2024-04-30T06:56:01.846+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:01:13.789783+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:56:01.849+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:01.848+0000] {taskinstance.py:2892} ERROR - {'DAG Id': 'tweets_dag_v2', 'Task Id': 'execute_python_script', 'Run Id': 'manual__2024-04-27T09:01:13.789783+00:00', 'Hostname': '586a550baf6e'}
[2024-04-30T06:56:01.855+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:01.855+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=tweets_dag_v2, task_id=execute_python_script, execution_date=20240427T090113, start_date=20240430T065024, end_date=20240430T065601
[2024-04-30T06:56:01.859+0000] {processor.py:791} INFO - Executed failure callback for <TaskInstance: tweets_dag_v2.execute_python_script manual__2024-04-27T09:01:13.789783+00:00 [up_for_retry]> in state up_for_retry
[2024-04-30T06:56:01.876+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:01.876+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:56:01.895+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:01.894+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:56:01.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.269 seconds
[2024-04-30T06:56:32.141+0000] {processor.py:161} INFO - Started process (PID=3287) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:56:32.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:56:32.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:32.143+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:56:35.144+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:56:35.173+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:35.172+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:56:35.201+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:56:35.200+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:56:35.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.090 seconds
[2024-04-30T06:57:07.130+0000] {processor.py:161} INFO - Started process (PID=3715) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:57:07.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:57:07.206+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:57:07.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:57:34.878+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:57:34.927+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:57:34.926+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:57:34.967+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:57:34.966+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:57:34.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 28.347 seconds
[2024-04-30T06:58:05.292+0000] {processor.py:161} INFO - Started process (PID=3761) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:58:05.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:58:05.304+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:58:05.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:58:08.503+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v2' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:58:08.527+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:58:08.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T06:58:08.549+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:58:08.549+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v2 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T06:58:08.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.380 seconds
[2024-04-30T06:58:38.881+0000] {processor.py:161} INFO - Started process (PID=3801) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:58:38.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:58:38.885+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:58:38.884+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:58:38.939+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:58:38.929+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T06:58:38.941+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:58:38.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.092 seconds
[2024-04-30T06:59:09.193+0000] {processor.py:161} INFO - Started process (PID=3829) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:59:09.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:59:09.196+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:59:09.195+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:59:09.231+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:59:09.223+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T06:59:09.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:59:09.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.068 seconds
[2024-04-30T06:59:39.479+0000] {processor.py:161} INFO - Started process (PID=3857) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:59:39.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T06:59:39.482+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:59:39.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:59:39.518+0000] {logging_mixin.py:188} INFO - [2024-04-30T06:59:39.510+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T06:59:39.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T06:59:39.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.066 seconds
[2024-04-30T07:00:09.762+0000] {processor.py:161} INFO - Started process (PID=3885) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:00:09.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:00:09.764+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:00:09.763+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:00:09.797+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:00:09.789+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:00:09.798+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:00:09.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.063 seconds
[2024-04-30T07:00:40.047+0000] {processor.py:161} INFO - Started process (PID=3913) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:00:40.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:00:40.050+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:00:40.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:00:40.086+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:00:40.078+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:00:40.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:00:40.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.066 seconds
[2024-04-30T07:01:10.329+0000] {processor.py:161} INFO - Started process (PID=3941) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:01:10.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:01:10.331+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:01:10.331+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:01:10.364+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:01:10.357+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:01:10.366+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:01:10.385+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.063 seconds
[2024-04-30T07:01:40.610+0000] {processor.py:161} INFO - Started process (PID=3969) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:01:40.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:01:40.612+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:01:40.612+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:01:40.644+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:01:40.638+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:01:40.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:01:40.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.061 seconds
[2024-04-30T07:02:10.881+0000] {processor.py:161} INFO - Started process (PID=3997) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:02:10.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:02:10.883+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:02:10.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:02:10.916+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:02:10.909+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:02:10.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:02:10.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.065 seconds
[2024-04-30T07:02:41.167+0000] {processor.py:161} INFO - Started process (PID=4025) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:02:41.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:02:41.170+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:02:41.169+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:02:41.206+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:02:41.198+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:02:41.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:02:41.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.068 seconds
[2024-04-30T07:03:11.445+0000] {processor.py:161} INFO - Started process (PID=4053) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:03:11.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:03:11.448+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:03:11.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:03:11.482+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:03:11.474+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:03:11.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:03:11.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.065 seconds
[2024-04-30T07:03:41.774+0000] {processor.py:161} INFO - Started process (PID=4081) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:03:41.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:03:41.776+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:03:41.776+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:03:41.824+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:03:41.812+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:03:41.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:03:41.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.083 seconds
[2024-04-30T07:04:12.071+0000] {processor.py:161} INFO - Started process (PID=4109) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:04:12.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:04:12.073+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:04:12.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:04:12.107+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:04:12.098+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:04:12.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:04:12.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.064 seconds
[2024-04-30T07:04:42.289+0000] {processor.py:161} INFO - Started process (PID=4124) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:04:42.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:04:42.292+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:04:42.292+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:04:42.326+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:04:42.319+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:04:42.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:04:42.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.067 seconds
[2024-04-30T07:05:12.577+0000] {processor.py:161} INFO - Started process (PID=4148) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:12.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:05:12.580+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:12.579+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:12.614+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:12.608+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:05:12.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:12.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.068 seconds
[2024-04-30T07:05:42.863+0000] {processor.py:161} INFO - Started process (PID=4176) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:42.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:05:42.866+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:42.865+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:42.905+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:42.897+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:05:42.907+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:42.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.073 seconds
[2024-04-30T07:05:49.379+0000] {processor.py:161} INFO - Started process (PID=4198) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:49.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:05:49.381+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:49.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:51.898+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:05:52.175+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:52.174+0000] {override.py:1829} INFO - Created Permission View: can read on DAG:tweets_dag_v3
[2024-04-30T07:05:52.192+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:52.191+0000] {override.py:1829} INFO - Created Permission View: can delete on DAG:tweets_dag_v3
[2024-04-30T07:05:52.202+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:52.202+0000] {override.py:1829} INFO - Created Permission View: can edit on DAG:tweets_dag_v3
[2024-04-30T07:05:52.203+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:52.203+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:05:52.226+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:52.225+0000] {dag.py:3118} INFO - Creating ORM DAG for tweets_dag_v3
[2024-04-30T07:05:52.246+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:05:52.245+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:05:52.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.909 seconds
[2024-04-30T07:06:22.481+0000] {processor.py:161} INFO - Started process (PID=4318) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:06:22.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:06:22.484+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:06:22.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:06:26.086+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:06:26.116+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:06:26.116+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:06:26.147+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:06:26.147+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T07:06:26.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.699 seconds
[2024-04-30T07:06:56.831+0000] {processor.py:161} INFO - Started process (PID=4495) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:06:56.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:06:56.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:06:56.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:07:10.985+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:07:11.058+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:07:11.057+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:07:11.099+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:07:11.098+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T07:07:11.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 14.325 seconds
[2024-04-30T07:07:41.272+0000] {processor.py:161} INFO - Started process (PID=4548) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:07:41.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:07:41.275+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:07:41.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:07:46.212+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:07:46.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:07:46.248+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:07:46.279+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:07:46.278+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T07:07:46.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 5.042 seconds
[2024-04-30T07:08:16.562+0000] {processor.py:161} INFO - Started process (PID=4648) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:08:16.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:08:16.565+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:08:16.564+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:08:19.173+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:08:19.197+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:08:19.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:08:19.220+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:08:19.219+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T07:08:19.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.684 seconds
[2024-04-30T07:08:49.517+0000] {processor.py:161} INFO - Started process (PID=4688) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:08:49.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:08:49.520+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:08:49.520+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:08:52.338+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:08:52.499+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:08:52.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:08:52.510+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:08:52.510+0000] {dag.py:3118} INFO - Creating ORM DAG for tweets_dag_v3
[2024-04-30T07:08:52.520+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:08:52.520+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:08:52.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.031 seconds
[2024-04-30T07:09:22.820+0000] {processor.py:161} INFO - Started process (PID=4728) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:09:22.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:09:22.828+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:09:22.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:09:26.171+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:09:26.198+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:09:26.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:09:26.222+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:09:26.222+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:09:26.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.448 seconds
[2024-04-30T07:09:56.373+0000] {processor.py:161} INFO - Started process (PID=4768) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:09:56.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:09:56.375+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:09:56.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:09:59.060+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:09:59.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:09:59.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:09:59.103+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:09:59.103+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:09:59.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.755 seconds
[2024-04-30T07:10:29.280+0000] {processor.py:161} INFO - Started process (PID=4814) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:10:29.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:10:29.282+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:10:29.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:10:31.827+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:10:31.850+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:10:31.849+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:10:31.871+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:10:31.871+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:10:31.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.619 seconds
[2024-04-30T07:11:02.031+0000] {processor.py:161} INFO - Started process (PID=4854) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:11:02.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:11:02.034+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:11:02.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:11:04.828+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:11:04.850+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:11:04.850+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:11:04.872+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:11:04.872+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:11:04.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.871 seconds
[2024-04-30T07:11:35.030+0000] {processor.py:161} INFO - Started process (PID=4894) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:11:35.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:11:35.032+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:11:35.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:11:37.702+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:11:37.728+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:11:37.728+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:11:37.750+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:11:37.750+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:11:37.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.749 seconds
[2024-04-30T07:12:07.985+0000] {processor.py:161} INFO - Started process (PID=4934) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:12:07.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:12:07.987+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:12:07.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:12:10.983+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:12:11.006+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:12:11.005+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:12:11.030+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:12:11.029+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:12:11.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.074 seconds
[2024-04-30T07:12:41.219+0000] {processor.py:161} INFO - Started process (PID=4974) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:12:41.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:12:41.222+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:12:41.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:12:44.011+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:12:44.033+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:12:44.033+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:12:44.058+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:12:44.058+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:12:44.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.874 seconds
[2024-04-30T07:13:14.231+0000] {processor.py:161} INFO - Started process (PID=5014) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:13:14.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:13:14.237+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:13:14.236+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:13:16.856+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:13:16.879+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:13:16.879+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:13:16.901+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:13:16.901+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:13:16.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.697 seconds
[2024-04-30T07:13:47.214+0000] {processor.py:161} INFO - Started process (PID=5054) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:13:47.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:13:47.216+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:13:47.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:13:49.855+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:13:49.880+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:13:49.880+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:13:49.903+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:13:49.903+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:13:49.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.719 seconds
[2024-04-30T07:14:20.091+0000] {processor.py:161} INFO - Started process (PID=5094) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:14:20.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:14:20.094+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:14:20.093+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:14:22.657+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:14:22.679+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:14:22.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:14:22.702+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:14:22.702+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:14:22.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.644 seconds
[2024-04-30T07:14:52.887+0000] {processor.py:161} INFO - Started process (PID=5134) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:14:52.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:14:52.890+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:14:52.889+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:14:56.117+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:14:56.155+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:14:56.155+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:14:56.187+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:14:56.187+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:14:56.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.337 seconds
[2024-04-30T07:15:26.325+0000] {processor.py:161} INFO - Started process (PID=5174) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:15:26.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:15:26.328+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:15:26.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:15:29.023+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:15:29.048+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:15:29.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:15:29.068+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:15:29.068+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:15:29.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.773 seconds
[2024-04-30T07:15:59.219+0000] {processor.py:161} INFO - Started process (PID=5214) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:15:59.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:15:59.221+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:15:59.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:16:01.900+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:16:01.924+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:16:01.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:16:01.946+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:16:01.946+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:16:01.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.757 seconds
[2024-04-30T07:16:32.085+0000] {processor.py:161} INFO - Started process (PID=5260) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:16:32.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:16:32.087+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:16:32.087+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:16:34.957+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:16:34.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:16:34.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:16:35.010+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:16:35.010+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:16:35.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.958 seconds
[2024-04-30T07:17:05.177+0000] {processor.py:161} INFO - Started process (PID=5300) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:17:05.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:17:05.179+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:17:05.179+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:17:07.836+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:17:07.861+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:17:07.860+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:17:07.884+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:17:07.883+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:17:07.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.738 seconds
[2024-04-30T07:17:38.108+0000] {processor.py:161} INFO - Started process (PID=5340) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:17:38.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:17:38.111+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:17:38.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:17:40.853+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:17:40.878+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:17:40.878+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:17:40.902+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:17:40.902+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:17:40.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.823 seconds
[2024-04-30T07:18:11.083+0000] {processor.py:161} INFO - Started process (PID=5380) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:18:11.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:18:11.086+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:18:11.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:18:13.839+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:18:13.868+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:18:13.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:18:13.891+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:18:13.891+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:18:13.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.837 seconds
[2024-04-30T07:18:44.263+0000] {processor.py:161} INFO - Started process (PID=5420) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:18:44.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:18:44.265+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:18:44.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:18:46.902+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:18:46.926+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:18:46.925+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:18:46.946+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:18:46.946+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:18:46.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.711 seconds
[2024-04-30T07:19:17.143+0000] {processor.py:161} INFO - Started process (PID=5460) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:19:17.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:19:17.146+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:19:17.145+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:19:19.782+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:19:19.808+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:19:19.808+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:19:19.829+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:19:19.829+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:19:19.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.712 seconds
[2024-04-30T07:19:49.998+0000] {processor.py:161} INFO - Started process (PID=5500) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:19:49.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:19:50.000+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:19:50.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:19:52.655+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:19:52.693+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:19:52.692+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:19:52.723+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:19:52.723+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:19:52.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.751 seconds
[2024-04-30T07:20:22.990+0000] {processor.py:161} INFO - Started process (PID=5540) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:20:22.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:20:22.993+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:20:22.992+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:20:25.654+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:20:25.685+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:20:25.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:20:25.707+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:20:25.707+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:20:25.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.743 seconds
[2024-04-30T07:20:55.879+0000] {processor.py:161} INFO - Started process (PID=5580) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:20:55.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:20:55.881+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:20:55.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:20:58.545+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:20:58.571+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:20:58.570+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:20:58.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:20:58.593+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:20:58.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.744 seconds
[2024-04-30T07:21:28.750+0000] {processor.py:161} INFO - Started process (PID=5620) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:21:28.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:21:28.752+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:21:28.752+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:21:31.351+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:21:31.376+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:21:31.375+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:21:31.398+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:21:31.398+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:21:31.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.676 seconds
[2024-04-30T07:22:01.576+0000] {processor.py:161} INFO - Started process (PID=5666) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:22:01.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:22:01.578+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:22:01.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:22:04.300+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:22:04.323+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:22:04.322+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:22:04.345+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:22:04.345+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:22:04.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.795 seconds
[2024-04-30T07:22:34.459+0000] {processor.py:161} INFO - Started process (PID=5706) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:22:34.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:22:34.461+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:22:34.461+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:22:37.090+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:22:37.114+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:22:37.114+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:22:37.135+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:22:37.135+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:22:37.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.704 seconds
[2024-04-30T07:23:07.352+0000] {processor.py:161} INFO - Started process (PID=5746) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:23:07.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:23:07.355+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:23:07.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:23:10.046+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:23:10.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:23:10.072+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:23:10.095+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:23:10.095+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:23:10.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.770 seconds
[2024-04-30T07:23:40.369+0000] {processor.py:161} INFO - Started process (PID=5786) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:23:40.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:23:40.371+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:23:40.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:23:43.055+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:23:43.079+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:23:43.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:23:43.101+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:23:43.101+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:23:43.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.758 seconds
[2024-04-30T07:24:13.255+0000] {processor.py:161} INFO - Started process (PID=5826) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:24:13.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:24:13.258+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:24:13.258+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:24:15.965+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:24:15.987+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:24:15.986+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:24:16.007+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:24:16.007+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:24:16.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.777 seconds
[2024-04-30T07:24:46.185+0000] {processor.py:161} INFO - Started process (PID=5866) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:24:46.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:24:46.188+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:24:46.187+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:24:48.707+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:24:48.729+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:24:48.729+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:24:48.749+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:24:48.748+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:24:48.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.589 seconds
[2024-04-30T07:25:18.950+0000] {processor.py:161} INFO - Started process (PID=5906) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:25:18.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:25:18.953+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:25:18.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:25:21.545+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:25:21.567+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:25:21.567+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:25:21.589+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:25:21.589+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:25:21.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.666 seconds
[2024-04-30T07:25:51.752+0000] {processor.py:161} INFO - Started process (PID=5946) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:25:51.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:25:51.754+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:25:51.754+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:25:54.503+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:25:54.549+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:25:54.549+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:25:54.575+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:25:54.575+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:25:54.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.854 seconds
[2024-04-30T07:26:24.834+0000] {processor.py:161} INFO - Started process (PID=5986) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:26:24.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:26:24.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:26:24.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:26:27.494+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:26:27.520+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:26:27.519+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:26:27.541+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:26:27.541+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:26:27.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.735 seconds
[2024-04-30T07:26:57.755+0000] {processor.py:161} INFO - Started process (PID=6026) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:26:57.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:26:57.758+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:26:57.758+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:27:00.660+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:27:00.690+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:27:00.689+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:27:00.714+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:27:00.713+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:27:00.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.995 seconds
[2024-04-30T07:27:30.891+0000] {processor.py:161} INFO - Started process (PID=6072) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:27:30.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:27:30.895+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:27:30.894+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:27:33.974+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:27:34.019+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:27:34.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:27:34.055+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:27:34.055+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:27:34.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.215 seconds
[2024-04-30T07:28:04.193+0000] {processor.py:161} INFO - Started process (PID=6112) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:28:04.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:28:04.195+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:28:04.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:28:06.803+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:28:06.825+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:28:06.824+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:28:06.847+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:28:06.847+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:28:06.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.684 seconds
[2024-04-30T07:28:37.132+0000] {processor.py:161} INFO - Started process (PID=6152) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:28:37.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:28:37.135+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:28:37.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:28:39.948+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:28:39.980+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:28:39.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:28:40.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:28:40.003+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:28:40.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.898 seconds
[2024-04-30T07:29:10.146+0000] {processor.py:161} INFO - Started process (PID=6192) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:29:10.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:29:10.148+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:29:10.148+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:29:12.838+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:29:12.863+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:29:12.863+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:29:12.888+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:29:12.888+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:29:12.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.775 seconds
[2024-04-30T07:29:43.070+0000] {processor.py:161} INFO - Started process (PID=6232) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:29:43.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:29:43.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:29:43.072+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:29:45.924+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:29:45.950+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:29:45.949+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:29:45.973+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:29:45.973+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:29:46.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.940 seconds
[2024-04-30T07:30:16.160+0000] {processor.py:161} INFO - Started process (PID=6272) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:30:16.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:30:16.162+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:30:16.162+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:30:18.711+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:30:18.736+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:30:18.735+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:30:18.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:30:18.756+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:30:18.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.623 seconds
[2024-04-30T07:30:48.955+0000] {processor.py:161} INFO - Started process (PID=6312) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:30:48.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:30:48.959+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:30:48.958+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:30:51.572+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:30:51.600+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:30:51.599+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:30:51.624+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:30:51.624+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:30:51.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.698 seconds
[2024-04-30T07:31:21.858+0000] {processor.py:161} INFO - Started process (PID=6352) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:31:21.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:31:21.860+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:31:21.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:31:24.588+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:31:24.617+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:31:24.617+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:31:24.639+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:31:24.638+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:31:24.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.809 seconds
[2024-04-30T07:31:54.840+0000] {processor.py:161} INFO - Started process (PID=6392) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:31:54.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:31:54.842+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:31:54.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:31:58.146+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:31:58.198+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:31:58.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:31:58.224+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:31:58.224+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:31:58.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.413 seconds
[2024-04-30T07:32:28.463+0000] {processor.py:161} INFO - Started process (PID=6432) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:32:28.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:32:28.466+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:32:28.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:32:31.762+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:32:31.789+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:32:31.788+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:32:31.815+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:32:31.814+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:32:31.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.385 seconds
[2024-04-30T07:33:01.985+0000] {processor.py:161} INFO - Started process (PID=6478) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:33:01.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:33:01.987+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:33:01.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:33:04.923+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:33:04.946+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:33:04.945+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:33:04.966+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:33:04.966+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:33:04.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.011 seconds
[2024-04-30T07:33:35.270+0000] {processor.py:161} INFO - Started process (PID=6518) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:33:35.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:33:35.272+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:33:35.272+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:33:38.123+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:33:38.147+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:33:38.146+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:33:38.168+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:33:38.168+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:33:38.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.931 seconds
[2024-04-30T07:34:08.318+0000] {processor.py:161} INFO - Started process (PID=6558) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:34:08.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:34:08.320+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:34:08.320+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:34:10.901+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:34:10.923+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:34:10.923+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:34:10.945+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:34:10.944+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:34:10.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.653 seconds
[2024-04-30T07:34:41.116+0000] {processor.py:161} INFO - Started process (PID=6598) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:34:41.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:34:41.118+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:34:41.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:34:43.612+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:34:43.635+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:34:43.635+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:34:43.656+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:34:43.656+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:34:43.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.567 seconds
[2024-04-30T07:35:13.835+0000] {processor.py:161} INFO - Started process (PID=6638) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:35:13.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:35:13.837+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:35:13.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:35:16.355+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:35:16.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:35:16.381+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:35:16.404+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:35:16.404+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:35:16.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.596 seconds
[2024-04-30T07:35:46.605+0000] {processor.py:161} INFO - Started process (PID=6678) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:35:46.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:35:46.607+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:35:46.607+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:35:49.196+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:35:49.218+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:35:49.218+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:35:49.238+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:35:49.238+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:35:49.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.661 seconds
[2024-04-30T07:36:19.400+0000] {processor.py:161} INFO - Started process (PID=6718) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:36:19.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:36:19.403+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:36:19.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:36:21.992+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:36:22.014+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:36:22.014+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:36:22.035+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:36:22.035+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:36:22.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.659 seconds
[2024-04-30T07:36:52.192+0000] {processor.py:161} INFO - Started process (PID=6758) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:36:52.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:36:52.194+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:36:52.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:36:54.807+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:36:54.831+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:36:54.831+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T07:36:54.852+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:36:54.852+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T07:36:54.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.686 seconds
[2024-04-30T07:37:25.071+0000] {processor.py:161} INFO - Started process (PID=6798) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:37:25.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:37:25.073+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:37:25.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:37:25.117+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:37:25.109+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 14, in <module>
    connect_to_database()
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in connect_to_database
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:37:25.119+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:37:25.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.081 seconds
[2024-04-30T07:37:55.369+0000] {processor.py:161} INFO - Started process (PID=6826) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:37:55.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:37:55.372+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:37:55.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:37:55.422+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:37:55.412+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:37:55.424+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:37:55.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.083 seconds
[2024-04-30T07:38:25.674+0000] {processor.py:161} INFO - Started process (PID=6854) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:38:25.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:38:25.676+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:38:25.676+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:38:25.711+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:38:25.703+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:38:25.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:38:25.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.067 seconds
[2024-04-30T07:38:55.966+0000] {processor.py:161} INFO - Started process (PID=6882) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:38:55.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:38:55.970+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:38:55.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:38:56.004+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:38:55.997+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:38:56.005+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:38:56.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.067 seconds
[2024-04-30T07:39:26.247+0000] {processor.py:161} INFO - Started process (PID=6910) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:39:26.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:39:26.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:39:26.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:39:26.281+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:39:26.274+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:39:26.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:39:26.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.064 seconds
[2024-04-30T07:39:56.523+0000] {processor.py:161} INFO - Started process (PID=6938) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:39:56.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:39:56.526+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:39:56.526+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:39:56.562+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:39:56.555+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:39:56.564+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:39:56.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.070 seconds
[2024-04-30T07:40:26.801+0000] {processor.py:161} INFO - Started process (PID=6966) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:40:26.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:40:26.803+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:40:26.803+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:40:26.847+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:40:26.841+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:40:26.849+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:40:26.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.075 seconds
[2024-04-30T07:40:57.072+0000] {processor.py:161} INFO - Started process (PID=6994) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:40:57.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:40:57.074+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:40:57.074+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:40:57.118+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:40:57.111+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:40:57.120+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:40:57.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.086 seconds
[2024-04-30T07:41:27.351+0000] {processor.py:161} INFO - Started process (PID=7022) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:41:27.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:41:27.353+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:41:27.353+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:41:27.389+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:41:27.381+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:41:27.391+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:41:27.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.067 seconds
[2024-04-30T07:41:57.643+0000] {processor.py:161} INFO - Started process (PID=7050) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:41:57.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:41:57.645+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:41:57.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:41:57.680+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:41:57.673+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:41:57.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:41:57.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.065 seconds
[2024-04-30T07:42:27.785+0000] {processor.py:161} INFO - Started process (PID=7078) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:42:27.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:42:27.788+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:42:27.788+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:42:27.829+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:42:27.820+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:42:27.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:42:27.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.085 seconds
[2024-04-30T07:42:57.999+0000] {processor.py:161} INFO - Started process (PID=7093) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:42:58.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:42:58.001+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:42:58.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:42:58.042+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:42:58.033+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:42:58.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:42:58.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.076 seconds
[2024-04-30T07:43:28.288+0000] {processor.py:161} INFO - Started process (PID=7117) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:43:28.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:43:28.291+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:43:28.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:43:28.325+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:43:28.318+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:43:28.327+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:43:28.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.066 seconds
[2024-04-30T07:43:58.715+0000] {processor.py:161} INFO - Started process (PID=7145) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:43:58.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:43:58.718+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:43:58.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:43:58.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:43:58.747+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:43:58.757+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:43:58.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.069 seconds
[2024-04-30T07:44:29.019+0000] {processor.py:161} INFO - Started process (PID=7173) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:44:29.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:44:29.022+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:44:29.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:44:29.057+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:44:29.049+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:44:29.058+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:44:29.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.067 seconds
[2024-04-30T07:44:59.304+0000] {processor.py:161} INFO - Started process (PID=7201) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:44:59.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:44:59.307+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:44:59.307+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:44:59.341+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:44:59.333+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:44:59.342+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:44:59.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.068 seconds
[2024-04-30T07:45:29.582+0000] {processor.py:161} INFO - Started process (PID=7229) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:45:29.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:45:29.585+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:45:29.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:45:29.630+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:45:29.623+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 4, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:45:29.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:45:29.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.076 seconds
[2024-04-30T07:45:59.883+0000] {processor.py:161} INFO - Started process (PID=7257) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:45:59.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:45:59.886+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:45:59.885+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:46:00.406+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:46:00.398+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:46:00.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:46:00.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.546 seconds
[2024-04-30T07:46:30.649+0000] {processor.py:161} INFO - Started process (PID=7286) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:46:30.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:46:30.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:46:30.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:46:31.141+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:46:31.132+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:46:31.142+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:46:31.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.515 seconds
[2024-04-30T07:47:01.380+0000] {processor.py:161} INFO - Started process (PID=7315) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:47:01.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:47:01.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:47:01.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:47:01.892+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:47:01.884+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:47:01.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:47:01.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.537 seconds
[2024-04-30T07:47:32.136+0000] {processor.py:161} INFO - Started process (PID=7350) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:47:32.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:47:32.138+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:47:32.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:47:32.631+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:47:32.623+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:47:32.633+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:47:32.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.520 seconds
[2024-04-30T07:48:02.791+0000] {processor.py:161} INFO - Started process (PID=7379) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:48:02.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:48:02.794+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:48:02.794+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:48:03.350+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:48:03.341+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:48:03.352+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:48:03.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.584 seconds
[2024-04-30T07:48:34.010+0000] {processor.py:161} INFO - Started process (PID=7408) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:48:34.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:48:34.013+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:48:34.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:48:34.523+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:48:34.514+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:48:34.524+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:48:34.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.539 seconds
[2024-04-30T07:49:04.690+0000] {processor.py:161} INFO - Started process (PID=7455) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:49:04.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:49:04.693+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:49:04.692+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:49:05.235+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:49:05.227+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:49:05.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:49:05.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.569 seconds
[2024-04-30T07:49:35.819+0000] {processor.py:161} INFO - Started process (PID=7490) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:49:35.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:49:35.822+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:49:35.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:49:36.320+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:49:36.312+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:49:36.321+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:49:36.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.524 seconds
[2024-04-30T07:50:06.674+0000] {processor.py:161} INFO - Started process (PID=7525) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:50:06.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:50:06.676+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:50:06.676+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:50:07.232+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:50:07.224+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:50:07.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:50:07.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.583 seconds
[2024-04-30T07:50:37.514+0000] {processor.py:161} INFO - Started process (PID=7547) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:50:37.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:50:37.517+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:50:37.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:50:38.134+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:50:38.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:50:38.135+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:50:38.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.645 seconds
[2024-04-30T07:51:08.866+0000] {processor.py:161} INFO - Started process (PID=7584) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:51:08.867+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:51:08.869+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:51:08.868+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:51:09.395+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:51:09.387+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:51:09.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:51:09.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.556 seconds
[2024-04-30T07:51:39.529+0000] {processor.py:161} INFO - Started process (PID=7619) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:51:39.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:51:39.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:51:39.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:51:40.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:51:39.994+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:51:40.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:51:40.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.497 seconds
[2024-04-30T07:52:10.225+0000] {processor.py:161} INFO - Started process (PID=7654) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:52:10.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:52:10.227+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:52:10.227+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:52:10.705+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:52:10.698+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:52:10.707+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:52:10.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.505 seconds
[2024-04-30T07:52:41.087+0000] {processor.py:161} INFO - Started process (PID=7689) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:52:41.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:52:41.089+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:52:41.089+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:52:41.570+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:52:41.561+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:52:41.572+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:52:41.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.508 seconds
[2024-04-30T07:53:12.093+0000] {processor.py:161} INFO - Started process (PID=7725) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:53:12.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:53:12.095+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:53:12.095+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:53:12.600+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:53:12.591+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:53:12.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:53:12.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.531 seconds
[2024-04-30T07:53:42.978+0000] {processor.py:161} INFO - Started process (PID=7760) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:53:42.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:53:42.981+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:53:42.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:53:43.616+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:53:43.607+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:53:43.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:53:43.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.663 seconds
[2024-04-30T07:54:13.891+0000] {processor.py:161} INFO - Started process (PID=7795) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:54:13.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:54:13.893+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:54:13.893+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:54:14.370+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:54:14.361+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:54:14.372+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:54:14.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.503 seconds
[2024-04-30T07:54:44.650+0000] {processor.py:161} INFO - Started process (PID=7830) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:54:44.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:54:44.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:54:44.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:54:45.168+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:54:45.160+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:54:45.170+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:54:45.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.542 seconds
[2024-04-30T07:55:15.909+0000] {processor.py:161} INFO - Started process (PID=7865) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:55:15.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:55:15.912+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:55:15.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:55:16.419+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:55:16.411+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 5, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:55:16.421+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:55:16.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.533 seconds
[2024-04-30T07:55:46.614+0000] {processor.py:161} INFO - Started process (PID=7906) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:55:46.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:55:46.616+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:55:46.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:55:47.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:55:47.135+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:55:47.146+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:55:47.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.555 seconds
[2024-04-30T07:56:17.851+0000] {processor.py:161} INFO - Started process (PID=7941) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:56:17.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:56:17.854+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:56:17.854+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:56:18.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:56:18.339+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:56:18.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:56:18.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.520 seconds
[2024-04-30T07:56:48.525+0000] {processor.py:161} INFO - Started process (PID=7976) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:56:48.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:56:48.527+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:56:48.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:56:49.055+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:56:49.046+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:56:49.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:56:49.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.555 seconds
[2024-04-30T07:57:19.681+0000] {processor.py:161} INFO - Started process (PID=8011) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:57:19.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:57:19.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:57:19.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:57:20.162+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:57:20.153+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:57:20.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:57:20.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.504 seconds
[2024-04-30T07:57:50.513+0000] {processor.py:161} INFO - Started process (PID=8046) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:57:50.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:57:50.516+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:57:50.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:57:50.993+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:57:50.984+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:57:50.994+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:57:51.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.505 seconds
[2024-04-30T07:58:21.602+0000] {processor.py:161} INFO - Started process (PID=8081) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:58:21.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:58:21.605+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:58:21.604+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:58:22.078+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:58:22.069+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:58:22.079+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:58:22.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.498 seconds
[2024-04-30T07:58:52.350+0000] {processor.py:161} INFO - Started process (PID=8103) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:58:52.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:58:52.353+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:58:52.352+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:58:52.923+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:58:52.915+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:58:52.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:58:52.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.596 seconds
[2024-04-30T07:59:23.202+0000] {processor.py:161} INFO - Started process (PID=8134) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:59:23.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:59:23.205+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:59:23.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:59:23.706+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:59:23.694+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:59:23.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:59:23.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.537 seconds
[2024-04-30T07:59:53.863+0000] {processor.py:161} INFO - Started process (PID=8169) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:59:53.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T07:59:53.865+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:59:53.865+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:59:54.355+0000] {logging_mixin.py:188} INFO - [2024-04-30T07:59:54.347+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T07:59:54.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T07:59:54.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.515 seconds
[2024-04-30T08:00:24.756+0000] {processor.py:161} INFO - Started process (PID=8204) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:00:24.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:00:24.758+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:00:24.758+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:00:25.231+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:00:25.223+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:00:25.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:00:25.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.503 seconds
[2024-04-30T08:00:55.509+0000] {processor.py:161} INFO - Started process (PID=8239) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:00:55.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:00:55.511+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:00:55.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:00:55.993+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:00:55.984+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:00:55.995+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:00:56.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.510 seconds
[2024-04-30T08:01:26.169+0000] {processor.py:161} INFO - Started process (PID=8274) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:01:26.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:01:26.172+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:01:26.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:01:26.650+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:01:26.643+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:01:26.651+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:01:26.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.503 seconds
[2024-04-30T08:01:56.741+0000] {processor.py:161} INFO - Started process (PID=8309) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:01:56.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:01:56.744+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:01:56.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:01:57.220+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:01:57.211+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:01:57.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:01:57.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.503 seconds
[2024-04-30T08:02:27.339+0000] {processor.py:161} INFO - Started process (PID=8344) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:02:27.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:02:27.341+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:02:27.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:02:27.830+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:02:27.821+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:02:27.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:02:27.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.515 seconds
[2024-04-30T08:02:57.942+0000] {processor.py:161} INFO - Started process (PID=8379) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:02:57.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:02:57.945+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:02:57.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:02:58.482+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:02:58.472+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:02:58.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:02:58.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.564 seconds
[2024-04-30T08:03:28.569+0000] {processor.py:161} INFO - Started process (PID=8414) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:03:28.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:03:28.572+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:03:28.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:03:29.043+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:03:29.036+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:03:29.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:03:29.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.498 seconds
[2024-04-30T08:03:59.187+0000] {processor.py:161} INFO - Started process (PID=8461) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:03:59.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:03:59.189+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:03:59.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:03:59.694+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:03:59.685+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:03:59.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:03:59.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.531 seconds
[2024-04-30T08:04:30.313+0000] {processor.py:161} INFO - Started process (PID=8508) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:04:30.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:04:30.316+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:04:30.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:04:30.803+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:04:30.794+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:04:30.805+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:04:30.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.515 seconds
[2024-04-30T08:05:01.088+0000] {processor.py:161} INFO - Started process (PID=8543) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:05:01.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:05:01.090+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:05:01.090+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:05:01.610+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:05:01.602+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:05:01.611+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:05:01.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.546 seconds
[2024-04-30T08:05:31.853+0000] {processor.py:161} INFO - Started process (PID=8578) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:05:31.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:05:31.856+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:05:31.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:05:32.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:05:32.339+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:05:32.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:05:32.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.518 seconds
[2024-04-30T08:06:03.122+0000] {processor.py:161} INFO - Started process (PID=8619) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:06:03.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:06:03.125+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:06:03.124+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:06:03.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:06:03.645+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:06:03.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:06:03.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.557 seconds
[2024-04-30T08:06:34.085+0000] {processor.py:161} INFO - Started process (PID=8660) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:06:34.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:06:34.087+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:06:34.087+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:06:34.578+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:06:34.569+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:06:34.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:06:34.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.516 seconds
[2024-04-30T08:07:04.713+0000] {processor.py:161} INFO - Started process (PID=8695) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:07:04.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:07:04.716+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:07:04.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:07:05.233+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:07:05.225+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:07:05.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:07:05.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.553 seconds
[2024-04-30T08:07:35.530+0000] {processor.py:161} INFO - Started process (PID=8717) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:07:35.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:07:35.534+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:07:35.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:07:36.095+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:07:36.086+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:07:36.097+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:07:36.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.591 seconds
[2024-04-30T08:08:06.785+0000] {processor.py:161} INFO - Started process (PID=8748) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:08:06.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:08:06.787+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:08:06.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:08:07.266+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:08:07.256+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:08:07.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:08:07.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.507 seconds
[2024-04-30T08:08:37.549+0000] {processor.py:161} INFO - Started process (PID=8783) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:08:37.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:08:37.551+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:08:37.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:08:38.047+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:08:38.040+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:08:38.049+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:08:38.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.522 seconds
[2024-04-30T08:09:08.353+0000] {processor.py:161} INFO - Started process (PID=8818) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:09:08.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:09:08.356+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:09:08.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:09:08.862+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:09:08.855+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:09:08.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:09:08.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.535 seconds
[2024-04-30T08:09:39.287+0000] {processor.py:161} INFO - Started process (PID=8859) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:09:39.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:09:39.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:09:39.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:09:39.796+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:09:39.786+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:09:39.797+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:09:39.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.534 seconds
[2024-04-30T08:10:10.376+0000] {processor.py:161} INFO - Started process (PID=8894) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:10:10.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:10:10.378+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:10:10.378+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:10:10.766+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:10:10.758+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:10:10.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:10:10.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.417 seconds
[2024-04-30T08:10:41.405+0000] {processor.py:161} INFO - Started process (PID=8929) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:10:41.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:10:41.407+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:10:41.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:10:41.744+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:10:41.735+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:10:41.745+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:10:41.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.365 seconds
[2024-04-30T08:11:12.185+0000] {processor.py:161} INFO - Started process (PID=8964) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:11:12.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:11:12.187+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:11:12.187+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:11:12.526+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:11:12.518+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:11:12.528+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:11:12.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.366 seconds
[2024-04-30T08:11:43.123+0000] {processor.py:161} INFO - Started process (PID=9000) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:11:43.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:11:43.126+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:11:43.125+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:11:43.480+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:11:43.471+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:11:43.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:11:43.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.383 seconds
[2024-04-30T08:12:13.707+0000] {processor.py:161} INFO - Started process (PID=9035) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:12:13.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:12:13.710+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:12:13.710+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:12:14.049+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:12:14.040+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:12:14.051+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:12:14.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.368 seconds
[2024-04-30T08:12:44.374+0000] {processor.py:161} INFO - Started process (PID=9076) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:12:44.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:12:44.376+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:12:44.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:12:44.712+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:12:44.703+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:12:44.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:12:44.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.365 seconds
[2024-04-30T08:13:15.037+0000] {processor.py:161} INFO - Started process (PID=9111) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:13:15.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:13:15.039+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:13:15.039+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:13:15.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:13:15.468+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:13:15.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:13:15.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.466 seconds
[2024-04-30T08:13:46.227+0000] {processor.py:161} INFO - Started process (PID=9146) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:13:46.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:13:46.232+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:13:46.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:13:47.239+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:13:47.222+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:13:47.242+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:13:47.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 1.080 seconds
[2024-04-30T08:14:17.650+0000] {processor.py:161} INFO - Started process (PID=9181) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:14:17.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:14:17.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:14:17.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:14:18.572+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:14:18.557+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:14:18.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:14:18.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.977 seconds
[2024-04-30T08:14:49.021+0000] {processor.py:161} INFO - Started process (PID=9203) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:14:49.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:14:49.029+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:14:49.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:14:50.102+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:14:50.078+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:14:50.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:14:50.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 1.159 seconds
[2024-04-30T08:15:20.430+0000] {processor.py:161} INFO - Started process (PID=9234) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:15:20.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:15:20.434+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:15:20.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:15:20.951+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:15:20.941+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:15:20.953+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:15:20.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.556 seconds
[2024-04-30T08:15:51.470+0000] {processor.py:161} INFO - Started process (PID=9269) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:15:51.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:15:51.473+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:15:51.472+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:15:52.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:15:51.990+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:15:52.006+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:15:52.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.576 seconds
[2024-04-30T08:16:22.359+0000] {processor.py:161} INFO - Started process (PID=9304) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:16:22.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:16:22.363+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:16:22.363+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:16:23.182+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:16:23.168+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:16:23.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:16:23.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.870 seconds
[2024-04-30T08:16:53.455+0000] {processor.py:161} INFO - Started process (PID=9339) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:16:53.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:16:53.461+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:16:53.460+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:16:54.423+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:16:54.411+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:16:54.427+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:16:54.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 1.030 seconds
[2024-04-30T08:17:24.746+0000] {processor.py:161} INFO - Started process (PID=9374) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:17:24.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:17:24.748+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:17:24.748+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:17:25.203+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:17:25.194+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:17:25.204+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:17:25.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.484 seconds
[2024-04-30T08:17:55.505+0000] {processor.py:161} INFO - Started process (PID=9409) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:17:55.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:17:55.507+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:17:55.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:17:56.145+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:17:56.135+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:17:56.148+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:17:56.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.683 seconds
[2024-04-30T08:18:26.312+0000] {processor.py:161} INFO - Started process (PID=9444) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:18:26.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:18:26.315+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:18:26.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:18:26.845+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:18:26.836+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:18:26.847+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:18:26.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.568 seconds
[2024-04-30T08:18:57.235+0000] {processor.py:161} INFO - Started process (PID=9466) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:18:57.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:18:57.238+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:18:57.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:18:57.748+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:18:57.740+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:18:57.750+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:18:57.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.543 seconds
[2024-04-30T08:19:28.056+0000] {processor.py:161} INFO - Started process (PID=9497) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:19:28.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:19:28.059+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:19:28.058+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:19:28.415+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:19:28.406+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:19:28.416+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:19:28.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.387 seconds
[2024-04-30T08:19:58.914+0000] {processor.py:161} INFO - Started process (PID=9532) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:19:58.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:19:58.917+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:19:58.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:19:59.283+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:19:59.275+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:19:59.285+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:19:59.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.395 seconds
[2024-04-30T08:20:29.821+0000] {processor.py:161} INFO - Started process (PID=9567) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:20:29.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:20:29.824+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:20:29.823+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:20:30.165+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:20:30.156+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:20:30.166+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:20:30.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.368 seconds
[2024-04-30T08:21:00.615+0000] {processor.py:161} INFO - Started process (PID=9602) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:21:00.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:21:00.617+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:21:00.617+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:21:00.961+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:21:00.951+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:21:00.963+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:21:00.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.373 seconds
[2024-04-30T08:21:31.593+0000] {processor.py:161} INFO - Started process (PID=9637) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:21:31.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:21:31.595+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:21:31.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:21:31.951+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:21:31.942+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:21:31.953+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:21:31.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.385 seconds
[2024-04-30T08:22:02.362+0000] {processor.py:161} INFO - Started process (PID=9672) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:22:02.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:22:02.364+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:22:02.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:22:02.693+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:22:02.685+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:22:02.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:22:02.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.355 seconds
[2024-04-30T08:22:33.053+0000] {processor.py:161} INFO - Started process (PID=9707) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:22:33.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:22:33.055+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:22:33.055+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:22:33.407+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:22:33.397+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:22:33.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:22:33.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.381 seconds
[2024-04-30T08:23:03.659+0000] {processor.py:161} INFO - Started process (PID=9742) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:23:03.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:23:03.661+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:23:03.660+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:23:04.050+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:23:04.041+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:23:04.051+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:23:04.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.417 seconds
[2024-04-30T08:23:34.587+0000] {processor.py:161} INFO - Started process (PID=9777) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:23:34.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:23:34.589+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:23:34.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:23:34.926+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:23:34.917+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
  File "/opt/airflow/dags/load_to_postgres.py", line 6, in <module>
    connection = psycopg2.connect(
                 ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 54321 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 54321 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-30T08:23:34.928+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:23:34.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.366 seconds
[2024-04-30T08:28:12.612+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:28:12.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:28:12.616+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:28:12.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:28:13.950+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:28:13.944+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
ImportError: cannot import name 'connect_to_database' from 'load_to_postgres' (/opt/airflow/dags/load_to_postgres.py)
[2024-04-30T08:28:13.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:28:13.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 1.367 seconds
[2024-04-30T08:28:44.272+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:28:44.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:28:44.282+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:28:44.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:28:44.961+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:28:44.955+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/twitter_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/twitter_data_dag.py", line 6, in <module>
    from load_to_postgres import connect_to_database
ImportError: cannot import name 'connect_to_database' from 'load_to_postgres' (/opt/airflow/dags/load_to_postgres.py)
[2024-04-30T08:28:44.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:28:44.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 0.725 seconds
[2024-04-30T08:29:00.817+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:00.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:29:00.820+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:00.819+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:03.567+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:03.817+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:03.817+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:29:03.840+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:03.840+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-26 00:00:00+00:00, run_after=2024-04-27 00:00:00+00:00
[2024-04-30T08:29:03.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.059 seconds
[2024-04-30T08:29:12.912+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:12.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:29:12.916+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:12.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:16.074+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:16.084+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:16.083+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:29:16.106+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:16.106+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:29:16.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.226 seconds
[2024-04-30T08:29:46.475+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:46.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:29:46.482+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:46.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:53.901+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:29:54.344+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:54.343+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:29:54.396+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:29:54.395+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:29:54.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 7.983 seconds
[2024-04-30T08:30:24.899+0000] {processor.py:161} INFO - Started process (PID=415) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:30:24.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:30:24.902+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:30:24.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:30:27.301+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:30:27.324+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:30:27.323+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:30:27.345+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:30:27.345+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:30:27.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.471 seconds
[2024-04-30T08:30:57.911+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:30:57.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:30:57.914+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:30:57.914+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:31:00.237+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:31:00.261+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:31:00.260+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:31:00.281+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:31:00.281+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:31:00.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.397 seconds
[2024-04-30T08:31:30.800+0000] {processor.py:161} INFO - Started process (PID=514) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:31:30.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:31:30.803+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:31:30.803+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:31:33.130+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:31:33.157+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:31:33.156+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:31:33.187+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:31:33.186+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:31:33.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.416 seconds
[2024-04-30T08:32:03.488+0000] {processor.py:161} INFO - Started process (PID=560) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:32:03.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:32:03.492+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:32:03.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:32:05.906+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:32:05.932+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:32:05.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:32:05.958+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:32:05.957+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:32:05.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.513 seconds
[2024-04-30T08:32:36.652+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:32:36.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:32:36.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:32:36.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:32:39.028+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:32:39.056+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:32:39.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:32:39.079+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:32:39.079+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:32:39.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.454 seconds
[2024-04-30T08:33:09.655+0000] {processor.py:161} INFO - Started process (PID=652) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:33:09.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:33:09.658+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:33:09.658+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:33:11.959+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:33:11.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:33:11.982+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:33:12.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:33:12.003+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:33:12.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.372 seconds
[2024-04-30T08:33:42.654+0000] {processor.py:161} INFO - Started process (PID=698) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:33:42.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:33:42.658+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:33:42.657+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:33:45.108+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:33:45.138+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:33:45.137+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:33:45.159+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:33:45.159+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:33:45.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.532 seconds
[2024-04-30T08:34:15.332+0000] {processor.py:161} INFO - Started process (PID=800) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:34:15.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:34:15.336+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:34:15.336+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:34:18.251+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:34:18.336+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:34:18.332+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:34:18.462+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:34:18.460+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:34:18.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.201 seconds
[2024-04-30T08:34:49.293+0000] {processor.py:161} INFO - Started process (PID=910) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:34:49.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:34:49.307+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:34:49.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:34:52.019+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:34:52.046+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:34:52.046+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:34:52.070+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:34:52.070+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:34:52.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.841 seconds
[2024-04-30T08:35:22.907+0000] {processor.py:161} INFO - Started process (PID=956) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:35:22.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:35:22.910+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:35:22.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:35:25.592+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:35:25.614+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:35:25.613+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:35:25.634+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:35:25.634+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:35:25.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.751 seconds
[2024-04-30T08:35:55.946+0000] {processor.py:161} INFO - Started process (PID=1002) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:35:55.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:35:55.949+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:35:55.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:35:58.354+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:35:58.378+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:35:58.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:35:58.402+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:35:58.402+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:35:58.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.483 seconds
[2024-04-30T08:36:28.698+0000] {processor.py:161} INFO - Started process (PID=1054) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:36:28.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:36:28.702+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:36:28.701+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:36:31.155+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:36:31.180+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:36:31.180+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:36:31.203+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:36:31.202+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:36:31.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.532 seconds
[2024-04-30T08:37:01.870+0000] {processor.py:161} INFO - Started process (PID=1103) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:37:01.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:37:01.874+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:37:01.874+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:37:04.401+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:37:04.426+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:37:04.426+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:37:04.450+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:37:04.450+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:37:04.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.609 seconds
[2024-04-30T08:37:35.045+0000] {processor.py:161} INFO - Started process (PID=1152) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:37:35.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:37:35.048+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:37:35.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:37:37.603+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:37:37.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:37:37.628+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:37:37.650+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:37:37.650+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:37:37.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.634 seconds
[2024-04-30T08:38:07.976+0000] {processor.py:161} INFO - Started process (PID=1199) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:38:07.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:38:07.979+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:38:07.978+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:38:10.355+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:38:10.379+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:38:10.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:38:10.401+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:38:10.401+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:38:10.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.450 seconds
[2024-04-30T08:38:41.157+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:38:41.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:38:41.161+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:38:41.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:38:43.470+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:38:43.494+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:38:43.493+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:38:43.520+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:38:43.520+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:38:43.547+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.397 seconds
[2024-04-30T08:39:13.951+0000] {processor.py:161} INFO - Started process (PID=1291) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:39:13.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:39:13.955+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:39:13.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:39:16.286+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:39:16.312+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:39:16.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:39:16.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:39:16.334+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:39:16.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.411 seconds
[2024-04-30T08:39:47.013+0000] {processor.py:161} INFO - Started process (PID=1365) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:39:47.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:39:47.018+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:39:47.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:39:49.361+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:39:49.385+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:39:49.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:39:49.406+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:39:49.406+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:39:49.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.417 seconds
[2024-04-30T08:40:19.730+0000] {processor.py:161} INFO - Started process (PID=1411) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:40:19.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:40:19.734+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:40:19.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:40:22.099+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:40:22.122+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:40:22.122+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:40:22.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:40:22.143+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:40:22.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.439 seconds
[2024-04-30T08:40:52.313+0000] {processor.py:161} INFO - Started process (PID=1457) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:40:52.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:40:52.317+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:40:52.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:40:54.690+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:40:54.715+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:40:54.715+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:40:54.736+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:40:54.735+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:40:54.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.448 seconds
[2024-04-30T08:41:24.944+0000] {processor.py:161} INFO - Started process (PID=1503) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:41:24.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:41:24.947+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:41:24.946+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:41:27.313+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:41:27.337+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:41:27.336+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:41:27.359+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:41:27.359+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:41:27.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.441 seconds
[2024-04-30T08:41:57.575+0000] {processor.py:161} INFO - Started process (PID=1549) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:41:57.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:41:57.579+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:41:57.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:41:59.934+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:41:59.960+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:41:59.960+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:41:59.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:41:59.982+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:42:00.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.434 seconds
[2024-04-30T08:42:30.240+0000] {processor.py:161} INFO - Started process (PID=1601) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:42:30.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:42:30.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:42:30.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:42:32.606+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:42:32.631+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:42:32.630+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:42:32.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:42:32.652+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:42:32.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.439 seconds
[2024-04-30T08:43:03.531+0000] {processor.py:161} INFO - Started process (PID=1697) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:43:03.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:43:03.536+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:43:03.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:43:06.493+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:43:06.529+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:43:06.528+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:43:06.555+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:43:06.554+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:43:06.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.060 seconds
[2024-04-30T08:43:36.688+0000] {processor.py:161} INFO - Started process (PID=1850) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:43:36.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:43:36.692+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:43:36.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:43:39.177+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:43:39.205+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:43:39.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:43:39.226+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:43:39.226+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:43:39.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.565 seconds
[2024-04-30T08:44:09.689+0000] {processor.py:161} INFO - Started process (PID=2080) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:44:09.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:44:09.707+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:09.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:44:17.017+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v3' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:44:17.121+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:17.120+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:44:17.156+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:17.155+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v3 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:44:17.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 7.655 seconds
[2024-04-30T08:44:38.822+0000] {processor.py:161} INFO - Started process (PID=2126) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:44:38.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:44:38.826+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:38.825+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:44:41.911+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:44:42.111+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:42.110+0000] {override.py:1829} INFO - Created Permission View: can read on DAG:tweets_dag_v4
[2024-04-30T08:44:42.124+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:42.124+0000] {override.py:1829} INFO - Created Permission View: can delete on DAG:tweets_dag_v4
[2024-04-30T08:44:42.134+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:42.134+0000] {override.py:1829} INFO - Created Permission View: can edit on DAG:tweets_dag_v4
[2024-04-30T08:44:42.135+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:42.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:44:42.150+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:42.150+0000] {dag.py:3118} INFO - Creating ORM DAG for tweets_dag_v4
[2024-04-30T08:44:42.162+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:44:42.162+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:44:42.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.371 seconds
[2024-04-30T08:45:12.344+0000] {processor.py:161} INFO - Started process (PID=2232) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:45:12.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:45:12.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:45:12.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:45:14.893+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:45:14.915+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:45:14.915+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:45:14.937+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:45:14.937+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:45:14.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.620 seconds
[2024-04-30T08:45:45.219+0000] {processor.py:161} INFO - Started process (PID=2279) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:45:45.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:45:45.223+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:45:45.223+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:45:47.698+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:45:47.725+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:45:47.725+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:45:47.751+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:45:47.750+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:45:47.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.563 seconds
[2024-04-30T08:46:18.222+0000] {processor.py:161} INFO - Started process (PID=2325) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:46:18.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:46:18.225+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:46:18.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:46:20.643+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:46:20.665+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:46:20.664+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:46:20.685+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:46:20.684+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:46:20.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.490 seconds
[2024-04-30T08:46:51.410+0000] {processor.py:161} INFO - Started process (PID=2371) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:46:51.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:46:51.414+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:46:51.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:46:53.838+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:46:53.868+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:46:53.868+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:46:53.897+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:46:53.897+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:46:53.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.519 seconds
[2024-04-30T08:47:24.289+0000] {processor.py:161} INFO - Started process (PID=2417) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:47:24.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:47:24.294+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:47:24.293+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:47:26.868+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:47:26.891+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:47:26.891+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:47:26.912+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:47:26.912+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:47:26.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.650 seconds
[2024-04-30T08:47:57.596+0000] {processor.py:161} INFO - Started process (PID=2463) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:47:57.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:47:57.601+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:47:57.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:48:00.299+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:48:00.337+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:48:00.336+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:48:00.364+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:48:00.364+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:48:00.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.799 seconds
[2024-04-30T08:48:30.731+0000] {processor.py:161} INFO - Started process (PID=2515) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:48:30.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:48:30.735+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:48:30.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:48:33.075+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:48:33.097+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:48:33.097+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:48:33.117+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:48:33.117+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:48:33.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.414 seconds
[2024-04-30T08:49:03.452+0000] {processor.py:161} INFO - Started process (PID=2567) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:49:03.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:49:03.456+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:49:03.455+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:49:06.167+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:49:06.192+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:49:06.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:49:06.215+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:49:06.215+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:49:06.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.795 seconds
[2024-04-30T08:49:36.783+0000] {processor.py:161} INFO - Started process (PID=2613) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:49:36.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:49:36.787+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:49:36.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:49:39.225+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:49:39.247+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:49:39.246+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:49:39.269+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:49:39.269+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:49:39.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.514 seconds
[2024-04-30T08:50:09.759+0000] {processor.py:161} INFO - Started process (PID=2673) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:50:09.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:50:09.764+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:50:09.763+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:50:12.304+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:50:12.327+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:50:12.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:50:12.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:50:12.347+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:50:12.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.615 seconds
[2024-04-30T08:50:43.029+0000] {processor.py:161} INFO - Started process (PID=2719) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:50:43.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:50:43.033+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:50:43.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:50:45.456+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:50:45.478+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:50:45.477+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:50:45.497+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:50:45.497+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:50:45.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.493 seconds
[2024-04-30T08:51:15.834+0000] {processor.py:161} INFO - Started process (PID=2765) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:51:15.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:51:15.838+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:51:15.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:51:18.244+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:51:18.266+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:51:18.266+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:51:18.287+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:51:18.286+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:51:18.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.478 seconds
[2024-04-30T08:51:48.992+0000] {processor.py:161} INFO - Started process (PID=2811) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:51:48.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:51:48.995+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:51:48.995+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:51:51.386+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:51:51.408+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:51:51.408+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:51:51.430+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:51:51.429+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:51:51.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.465 seconds
[2024-04-30T08:52:21.809+0000] {processor.py:161} INFO - Started process (PID=2857) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:52:21.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:52:21.813+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:52:21.812+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:52:24.194+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:52:24.222+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:52:24.221+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:52:24.246+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:52:24.246+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:52:24.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.466 seconds
[2024-04-30T08:52:54.878+0000] {processor.py:161} INFO - Started process (PID=2903) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:52:54.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:52:54.881+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:52:54.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:52:57.262+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:52:57.284+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:52:57.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:52:57.303+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:52:57.303+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:52:57.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.451 seconds
[2024-04-30T08:53:27.485+0000] {processor.py:161} INFO - Started process (PID=2949) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:53:27.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:53:27.489+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:53:27.488+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:53:29.866+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:53:29.889+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:53:29.889+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:53:29.914+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:53:29.913+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:53:29.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.454 seconds
[2024-04-30T08:54:00.216+0000] {processor.py:161} INFO - Started process (PID=2988) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:54:00.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:54:00.220+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:54:00.219+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:54:02.738+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:54:02.762+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:54:02.761+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:54:02.785+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:54:02.784+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:54:02.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.596 seconds
[2024-04-30T08:54:33.197+0000] {processor.py:161} INFO - Started process (PID=3068) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:54:33.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:54:33.200+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:54:33.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:54:36.008+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:54:36.050+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:54:36.049+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:54:36.080+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:54:36.080+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:54:36.108+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.920 seconds
[2024-04-30T08:55:06.366+0000] {processor.py:161} INFO - Started process (PID=3146) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:55:06.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:55:06.369+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:55:06.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:55:08.876+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:55:08.919+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:55:08.918+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:55:08.955+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:55:08.955+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:55:08.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.615 seconds
[2024-04-30T08:55:39.248+0000] {processor.py:161} INFO - Started process (PID=3192) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:55:39.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:55:39.252+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:55:39.251+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:55:41.862+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:55:41.886+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:55:41.886+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:55:41.910+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:55:41.909+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:55:41.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.688 seconds
[2024-04-30T08:56:12.210+0000] {processor.py:161} INFO - Started process (PID=3238) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:56:12.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:56:12.213+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:56:12.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:56:14.862+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:56:14.886+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:56:14.885+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:56:14.909+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:56:14.909+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:56:14.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.727 seconds
[2024-04-30T08:56:45.207+0000] {processor.py:161} INFO - Started process (PID=3344) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:56:45.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:56:45.211+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:56:45.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:56:47.886+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:56:47.910+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:56:47.909+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:56:47.931+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:56:47.930+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:56:47.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.751 seconds
[2024-04-30T08:57:18.148+0000] {processor.py:161} INFO - Started process (PID=3409) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:57:18.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:57:18.152+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:57:18.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:57:20.917+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:57:20.988+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:57:20.987+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:57:21.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:57:21.012+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:57:21.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.890 seconds
[2024-04-30T08:57:51.298+0000] {processor.py:161} INFO - Started process (PID=3514) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:57:51.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:57:51.302+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:57:51.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:57:53.862+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:57:53.888+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:57:53.887+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:57:53.912+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:57:53.912+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:57:53.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.642 seconds
[2024-04-30T08:58:24.383+0000] {processor.py:161} INFO - Started process (PID=3566) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:58:24.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:58:24.387+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:58:24.387+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:58:27.403+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:58:27.439+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:58:27.438+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:58:27.471+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:58:27.471+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:58:27.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.122 seconds
[2024-04-30T08:58:57.597+0000] {processor.py:161} INFO - Started process (PID=3685) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:58:57.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:58:57.601+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:58:57.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:59:00.163+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:59:00.187+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:59:00.187+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:59:00.207+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:59:00.207+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:59:00.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.636 seconds
[2024-04-30T08:59:30.484+0000] {processor.py:161} INFO - Started process (PID=3737) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:59:30.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T08:59:30.487+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:59:30.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:59:32.933+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T08:59:32.956+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:59:32.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T08:59:32.976+0000] {logging_mixin.py:188} INFO - [2024-04-30T08:59:32.975+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T08:59:32.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.516 seconds
[2024-04-30T09:00:03.151+0000] {processor.py:161} INFO - Started process (PID=3829) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:00:03.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:00:03.156+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:00:03.155+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:00:07.856+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:00:07.900+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:00:07.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:00:07.950+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:00:07.949+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:00:07.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 4.851 seconds
[2024-04-30T09:00:38.436+0000] {processor.py:161} INFO - Started process (PID=3889) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:00:38.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:00:38.439+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:00:38.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:00:40.973+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:00:40.997+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:00:40.997+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:00:41.019+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:00:41.019+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:00:41.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.610 seconds
[2024-04-30T09:01:11.673+0000] {processor.py:161} INFO - Started process (PID=3935) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:01:11.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:01:11.676+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:01:11.676+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:01:14.091+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:01:14.116+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:01:14.115+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:01:14.136+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:01:14.135+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:01:14.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.490 seconds
[2024-04-30T09:01:44.376+0000] {processor.py:161} INFO - Started process (PID=3981) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:01:44.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:01:44.380+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:01:44.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:01:46.838+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:01:46.861+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:01:46.860+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:01:46.886+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:01:46.885+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:01:46.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.537 seconds
[2024-04-30T09:02:17.125+0000] {processor.py:161} INFO - Started process (PID=4027) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:02:17.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:02:17.128+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:02:17.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:02:19.623+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:02:19.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:02:19.645+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:02:19.668+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:02:19.667+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:02:19.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.573 seconds
[2024-04-30T09:02:49.867+0000] {processor.py:161} INFO - Started process (PID=4073) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:02:49.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:02:49.871+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:02:49.870+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:02:52.345+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:02:52.366+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:02:52.366+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:02:52.388+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:02:52.388+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:02:52.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.547 seconds
[2024-04-30T09:03:22.781+0000] {processor.py:161} INFO - Started process (PID=4119) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:03:22.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:03:22.784+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:03:22.784+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:03:25.316+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:03:25.340+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:03:25.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:03:25.359+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:03:25.359+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:03:25.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.604 seconds
[2024-04-30T09:03:55.592+0000] {processor.py:161} INFO - Started process (PID=4165) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:03:55.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:03:55.595+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:03:55.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:03:58.058+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:03:58.080+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:03:58.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:03:58.099+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:03:58.099+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:03:58.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.532 seconds
[2024-04-30T09:04:28.191+0000] {processor.py:161} INFO - Started process (PID=4211) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:04:28.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:04:28.194+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:04:28.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:04:30.686+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:04:30.708+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:04:30.708+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:04:30.730+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:04:30.730+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:04:30.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.565 seconds
[2024-04-30T09:05:00.907+0000] {processor.py:161} INFO - Started process (PID=4263) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:05:00.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:05:00.911+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:05:00.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:05:03.395+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:05:03.417+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:05:03.417+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:05:03.439+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:05:03.439+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:05:03.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.557 seconds
[2024-04-30T09:05:33.740+0000] {processor.py:161} INFO - Started process (PID=4309) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:05:33.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:05:33.743+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:05:33.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:05:36.278+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:05:36.303+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:05:36.303+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:05:36.324+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:05:36.324+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:05:36.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.610 seconds
[2024-04-30T09:06:06.923+0000] {processor.py:161} INFO - Started process (PID=4361) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:06:06.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:06:06.927+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:06:06.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:06:09.418+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:06:09.441+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:06:09.440+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:06:09.461+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:06:09.461+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:06:09.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.563 seconds
[2024-04-30T09:06:39.685+0000] {processor.py:161} INFO - Started process (PID=4407) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:06:39.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:06:39.689+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:06:39.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:06:42.171+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:06:42.195+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:06:42.194+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:06:42.215+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:06:42.215+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:06:42.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.555 seconds
[2024-04-30T09:07:12.481+0000] {processor.py:161} INFO - Started process (PID=4453) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:07:12.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:07:12.484+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:07:12.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:07:14.965+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:07:14.992+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:07:14.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:07:15.016+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:07:15.016+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:07:15.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.564 seconds
[2024-04-30T09:07:45.204+0000] {processor.py:161} INFO - Started process (PID=4499) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:07:45.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:07:45.207+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:07:45.207+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:07:47.709+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:07:47.735+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:07:47.735+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:07:47.759+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:07:47.759+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:07:47.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.584 seconds
[2024-04-30T09:08:18.031+0000] {processor.py:161} INFO - Started process (PID=4545) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:08:18.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:08:18.034+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:08:18.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:08:20.551+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:08:20.573+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:08:20.573+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:08:20.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:08:20.593+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:08:20.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.587 seconds
[2024-04-30T09:08:50.723+0000] {processor.py:161} INFO - Started process (PID=4591) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:08:50.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:08:50.726+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:08:50.726+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:08:53.199+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:08:53.224+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:08:53.224+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:08:53.246+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:08:53.246+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:08:53.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.552 seconds
[2024-04-30T09:09:23.510+0000] {processor.py:161} INFO - Started process (PID=4637) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:09:23.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:09:23.514+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:09:23.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:09:26.059+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:09:26.083+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:09:26.083+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:09:26.106+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:09:26.105+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:09:26.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.622 seconds
[2024-04-30T09:09:56.240+0000] {processor.py:161} INFO - Started process (PID=4683) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:09:56.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:09:56.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:09:56.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:09:58.748+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:09:58.772+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:09:58.771+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:09:58.793+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:09:58.793+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:09:58.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.581 seconds
[2024-04-30T09:10:29.076+0000] {processor.py:161} INFO - Started process (PID=4730) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:10:29.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:10:29.079+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:10:29.079+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:10:31.658+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:10:31.680+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:10:31.680+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:10:31.701+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:10:31.701+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:10:31.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.650 seconds
[2024-04-30T09:11:01.884+0000] {processor.py:161} INFO - Started process (PID=4782) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:11:01.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:11:01.887+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:11:01.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:11:04.381+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:11:04.406+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:11:04.405+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:11:04.427+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:11:04.427+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:11:04.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.570 seconds
[2024-04-30T09:11:34.617+0000] {processor.py:161} INFO - Started process (PID=4828) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:11:34.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:11:34.620+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:11:34.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:11:37.086+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:11:37.109+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:11:37.109+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:11:37.131+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:11:37.131+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:11:37.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.542 seconds
[2024-04-30T09:12:07.287+0000] {processor.py:161} INFO - Started process (PID=4874) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:12:07.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:12:07.291+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:12:07.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:12:09.717+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:12:09.741+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:12:09.740+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:12:09.764+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:12:09.763+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:12:09.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.507 seconds
[2024-04-30T09:12:40.089+0000] {processor.py:161} INFO - Started process (PID=4920) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:12:40.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:12:40.092+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:12:40.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:12:42.503+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:12:42.527+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:12:42.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:12:42.549+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:12:42.549+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:12:42.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.487 seconds
[2024-04-30T09:13:13.003+0000] {processor.py:161} INFO - Started process (PID=4966) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:13:13.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:13:13.007+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:13:13.006+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:13:15.516+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:13:15.543+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:13:15.543+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:13:15.574+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:13:15.574+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:13:15.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.598 seconds
[2024-04-30T09:13:45.861+0000] {processor.py:161} INFO - Started process (PID=5012) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:13:45.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:13:45.865+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:13:45.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:13:48.359+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:13:48.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:13:48.382+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:13:48.406+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:13:48.406+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:13:48.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.583 seconds
[2024-04-30T09:14:18.679+0000] {processor.py:161} INFO - Started process (PID=5058) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:14:18.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:14:18.682+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:14:18.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:14:21.109+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:14:21.133+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:14:21.133+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:14:21.154+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:14:21.154+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:14:21.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.503 seconds
[2024-04-30T09:14:51.340+0000] {processor.py:161} INFO - Started process (PID=5110) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:14:51.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:14:51.343+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:14:51.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:14:53.845+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:14:53.870+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:14:53.869+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:14:53.891+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:14:53.891+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:14:53.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.578 seconds
[2024-04-30T09:15:24.158+0000] {processor.py:161} INFO - Started process (PID=5156) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:15:24.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:15:24.161+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:15:24.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:15:26.570+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:15:26.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:15:26.593+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:15:26.616+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:15:26.615+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:15:26.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.483 seconds
[2024-04-30T09:15:56.940+0000] {processor.py:161} INFO - Started process (PID=5202) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:15:56.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:15:56.943+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:15:56.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:15:59.537+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:15:59.561+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:15:59.561+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:15:59.583+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:15:59.583+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:15:59.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.670 seconds
[2024-04-30T09:16:29.768+0000] {processor.py:161} INFO - Started process (PID=5248) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:16:29.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:16:29.772+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:16:29.771+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:16:32.114+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:16:32.139+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:16:32.138+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:16:32.162+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:16:32.162+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:16:32.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.423 seconds
[2024-04-30T09:17:02.531+0000] {processor.py:161} INFO - Started process (PID=5300) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:17:02.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:17:02.534+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:17:02.534+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:17:04.906+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:17:04.930+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:17:04.930+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:17:04.953+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:17:04.952+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:17:04.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.449 seconds
[2024-04-30T09:17:35.361+0000] {processor.py:161} INFO - Started process (PID=5346) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:17:35.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:17:35.366+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:17:35.365+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:17:37.748+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:17:37.774+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:17:37.774+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:17:37.799+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:17:37.799+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:17:37.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.469 seconds
[2024-04-30T09:18:08.122+0000] {processor.py:161} INFO - Started process (PID=5392) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:18:08.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:18:08.126+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:18:08.126+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:18:10.431+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:18:10.458+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:18:10.457+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:18:10.480+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:18:10.480+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:18:10.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.386 seconds
[2024-04-30T09:18:40.975+0000] {processor.py:161} INFO - Started process (PID=5438) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:18:40.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:18:40.978+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:18:40.978+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:18:43.290+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:18:43.314+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:18:43.313+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:18:43.338+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:18:43.337+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:18:43.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.394 seconds
[2024-04-30T09:19:13.754+0000] {processor.py:161} INFO - Started process (PID=5484) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:19:13.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:19:13.757+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:19:13.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:19:16.099+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:19:16.122+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:19:16.122+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:19:16.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:19:16.144+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:19:16.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.415 seconds
[2024-04-30T09:19:46.601+0000] {processor.py:161} INFO - Started process (PID=5530) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:19:46.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:19:46.605+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:19:46.604+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:19:48.904+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:19:48.930+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:19:48.929+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:19:48.958+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:19:48.957+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:19:48.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.383 seconds
[2024-04-30T09:20:19.362+0000] {processor.py:161} INFO - Started process (PID=5576) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:20:19.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:20:19.366+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:20:19.365+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:20:21.628+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:20:21.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:20:21.651+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:20:21.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:20:21.673+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:20:21.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.336 seconds
[2024-04-30T09:20:52.172+0000] {processor.py:161} INFO - Started process (PID=5622) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:20:52.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:20:52.175+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:20:52.175+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:20:54.481+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:20:54.506+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:20:54.506+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:20:54.528+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:20:54.527+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:20:54.547+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.382 seconds
[2024-04-30T09:21:24.919+0000] {processor.py:161} INFO - Started process (PID=5668) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:21:24.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:21:24.922+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:21:24.922+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:21:27.254+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:21:27.277+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:21:27.277+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:21:27.300+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:21:27.299+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:21:27.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.407 seconds
[2024-04-30T09:21:57.704+0000] {processor.py:161} INFO - Started process (PID=5714) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:21:57.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:21:57.708+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:21:57.707+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:22:00.032+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:22:00.059+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:22:00.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:22:00.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:22:00.082+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:22:00.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.404 seconds
[2024-04-30T09:22:30.384+0000] {processor.py:161} INFO - Started process (PID=5760) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:22:30.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:22:30.387+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:22:30.387+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:22:32.713+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:22:32.737+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:22:32.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:22:32.761+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:22:32.761+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:22:32.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.403 seconds
[2024-04-30T09:23:03.054+0000] {processor.py:161} INFO - Started process (PID=5812) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:23:03.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:23:03.058+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:23:03.057+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:23:05.405+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:23:05.430+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:23:05.429+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:23:05.451+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:23:05.450+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:23:05.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.422 seconds
[2024-04-30T09:23:35.928+0000] {processor.py:161} INFO - Started process (PID=5864) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:23:35.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:23:35.932+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:23:35.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:23:38.228+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:23:38.251+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:23:38.251+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:23:38.272+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:23:38.272+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:23:38.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.371 seconds
[2024-04-30T09:24:08.647+0000] {processor.py:161} INFO - Started process (PID=5910) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:24:08.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:24:08.650+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:24:08.650+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:24:10.932+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:24:10.955+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:24:10.955+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:24:10.977+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:24:10.977+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:24:10.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.355 seconds
[2024-04-30T09:24:41.302+0000] {processor.py:161} INFO - Started process (PID=5956) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:24:41.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:24:41.306+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:24:41.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:24:43.627+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:24:43.651+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:24:43.651+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:24:43.674+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:24:43.674+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:24:43.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.401 seconds
[2024-04-30T09:25:14.013+0000] {processor.py:161} INFO - Started process (PID=6002) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:25:14.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:25:14.017+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:25:14.016+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:25:16.345+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:25:16.369+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:25:16.369+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:25:16.390+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:25:16.390+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:25:16.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.405 seconds
[2024-04-30T09:25:46.716+0000] {processor.py:161} INFO - Started process (PID=6048) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:25:46.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:25:46.720+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:25:46.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:25:49.061+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:25:49.085+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:25:49.084+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:25:49.106+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:25:49.105+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:25:49.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.416 seconds
[2024-04-30T09:26:19.351+0000] {processor.py:161} INFO - Started process (PID=6094) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:26:19.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:26:19.354+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:26:19.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:26:21.632+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:26:21.656+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:26:21.655+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:26:21.679+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:26:21.679+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:26:21.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.355 seconds
[2024-04-30T09:26:52.000+0000] {processor.py:161} INFO - Started process (PID=6140) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:26:52.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:26:52.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:26:52.003+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:26:54.308+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:26:54.332+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:26:54.331+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:26:54.355+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:26:54.355+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:26:54.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.384 seconds
[2024-04-30T09:27:24.702+0000] {processor.py:161} INFO - Started process (PID=6186) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:27:24.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:27:24.706+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:27:24.705+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:27:27.051+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:27:27.076+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:27:27.076+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:27:27.098+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:27:27.098+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:27:27.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.422 seconds
[2024-04-30T09:27:57.380+0000] {processor.py:161} INFO - Started process (PID=6232) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:27:57.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:27:57.383+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:27:57.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:27:59.715+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:27:59.737+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:27:59.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:27:59.760+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:27:59.759+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:27:59.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.407 seconds
[2024-04-30T09:28:30.185+0000] {processor.py:161} INFO - Started process (PID=6278) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:28:30.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:28:30.188+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:28:30.188+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:28:32.564+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:28:32.588+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:28:32.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:28:32.609+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:28:32.608+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:28:32.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.451 seconds
[2024-04-30T09:29:02.781+0000] {processor.py:161} INFO - Started process (PID=6330) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:29:02.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:29:02.784+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:29:02.784+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:29:05.090+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:29:05.114+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:29:05.114+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:29:05.136+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:29:05.136+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:29:05.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.381 seconds
[2024-04-30T09:29:35.438+0000] {processor.py:161} INFO - Started process (PID=6376) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:29:35.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:29:35.441+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:29:35.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:29:37.840+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:29:37.864+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:29:37.864+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:29:37.885+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:29:37.885+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:29:37.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.474 seconds
[2024-04-30T09:30:08.169+0000] {processor.py:161} INFO - Started process (PID=6422) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:30:08.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:30:08.172+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:30:08.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:30:10.522+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:30:10.546+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:30:10.545+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:30:10.568+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:30:10.568+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:30:10.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.427 seconds
[2024-04-30T09:30:40.856+0000] {processor.py:161} INFO - Started process (PID=6468) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:30:40.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:30:40.860+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:30:40.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:30:43.158+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:30:43.181+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:30:43.181+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:30:43.203+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:30:43.203+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:30:43.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.376 seconds
[2024-04-30T09:31:13.505+0000] {processor.py:161} INFO - Started process (PID=6514) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:31:13.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:31:13.508+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:31:13.508+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:31:15.859+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:31:15.884+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:31:15.883+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:31:15.907+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:31:15.907+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:31:15.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.427 seconds
[2024-04-30T09:31:46.188+0000] {processor.py:161} INFO - Started process (PID=6564) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:31:46.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:31:46.192+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:31:46.192+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:31:48.509+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:31:48.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:31:48.532+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:31:48.553+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:31:48.553+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:31:48.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.400 seconds
[2024-04-30T09:32:18.841+0000] {processor.py:161} INFO - Started process (PID=6612) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:32:18.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:32:18.845+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:32:18.844+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:32:21.180+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:32:21.203+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:32:21.202+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:32:21.224+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:32:21.224+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:32:21.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.410 seconds
[2024-04-30T09:32:51.431+0000] {processor.py:161} INFO - Started process (PID=6658) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:32:51.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:32:51.434+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:32:51.434+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:32:53.749+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:32:53.773+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:32:53.773+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:32:53.796+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:32:53.796+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:32:53.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.393 seconds
[2024-04-30T09:33:24.148+0000] {processor.py:161} INFO - Started process (PID=6704) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:33:24.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:33:24.151+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:33:24.151+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:33:26.532+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:33:26.556+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:33:26.555+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:33:26.579+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:33:26.578+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:33:26.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.456 seconds
[2024-04-30T09:33:56.794+0000] {processor.py:161} INFO - Started process (PID=6750) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:33:56.796+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:33:56.798+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:33:56.797+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:33:59.155+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:33:59.182+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:33:59.182+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:33:59.205+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:33:59.205+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:33:59.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.437 seconds
[2024-04-30T09:34:29.441+0000] {processor.py:161} INFO - Started process (PID=6796) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:34:29.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:34:29.445+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:34:29.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:34:31.797+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:34:31.820+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:34:31.820+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:34:31.843+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:34:31.842+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:34:31.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.431 seconds
[2024-04-30T09:35:02.068+0000] {processor.py:161} INFO - Started process (PID=6848) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:35:02.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:35:02.071+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:35:02.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:35:04.381+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:35:04.404+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:35:04.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:35:04.426+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:35:04.426+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:35:04.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.388 seconds
[2024-04-30T09:35:34.695+0000] {processor.py:161} INFO - Started process (PID=6894) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:35:34.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:35:34.698+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:35:34.698+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:35:37.067+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:35:37.092+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:35:37.091+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:35:37.115+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:35:37.114+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:35:37.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.445 seconds
[2024-04-30T09:36:07.393+0000] {processor.py:161} INFO - Started process (PID=6940) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:36:07.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:36:07.397+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:36:07.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:36:09.789+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:36:09.813+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:36:09.813+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:36:09.833+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:36:09.833+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:36:09.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.466 seconds
[2024-04-30T09:36:40.113+0000] {processor.py:161} INFO - Started process (PID=6986) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:36:40.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:36:40.116+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:36:40.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:36:42.473+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:36:42.497+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:36:42.497+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:36:42.519+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:36:42.519+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:36:42.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.433 seconds
[2024-04-30T09:37:12.801+0000] {processor.py:161} INFO - Started process (PID=7032) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:37:12.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:37:12.805+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:37:12.804+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:37:15.154+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:37:15.178+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:37:15.178+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:37:15.200+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:37:15.200+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:37:15.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.424 seconds
[2024-04-30T09:37:45.488+0000] {processor.py:161} INFO - Started process (PID=7078) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:37:45.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:37:45.492+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:37:45.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:37:47.873+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:37:47.896+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:37:47.896+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:37:47.919+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:37:47.919+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:37:47.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.457 seconds
[2024-04-30T09:38:18.277+0000] {processor.py:161} INFO - Started process (PID=7124) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:38:18.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:38:18.280+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:38:18.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:38:20.663+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:38:20.688+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:38:20.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:38:20.712+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:38:20.712+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:38:20.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.461 seconds
[2024-04-30T09:38:50.880+0000] {processor.py:161} INFO - Started process (PID=7170) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:38:50.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:38:50.883+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:38:50.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:38:53.287+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:38:53.310+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:38:53.310+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:38:53.331+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:38:53.331+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:38:53.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.476 seconds
[2024-04-30T09:39:23.526+0000] {processor.py:161} INFO - Started process (PID=7216) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:39:23.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:39:23.529+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:39:23.528+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:39:25.827+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:39:25.854+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:39:25.854+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:39:25.877+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:39:25.877+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:39:25.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.378 seconds
[2024-04-30T09:39:56.173+0000] {processor.py:161} INFO - Started process (PID=7262) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:39:56.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:39:56.176+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:39:56.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:39:58.565+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:39:58.588+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:39:58.588+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:39:58.618+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:39:58.617+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:39:58.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.471 seconds
[2024-04-30T09:40:28.826+0000] {processor.py:161} INFO - Started process (PID=7314) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:40:28.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:40:28.830+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:40:28.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:40:31.277+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:40:31.301+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:40:31.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:40:31.322+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:40:31.322+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:40:31.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.523 seconds
[2024-04-30T09:41:01.598+0000] {processor.py:161} INFO - Started process (PID=7360) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:41:01.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:41:01.601+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:41:01.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:41:03.963+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:41:03.989+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:41:03.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:41:04.009+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:41:04.009+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:41:04.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.438 seconds
[2024-04-30T09:41:34.236+0000] {processor.py:161} INFO - Started process (PID=7412) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:41:34.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:41:34.240+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:41:34.239+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:41:36.538+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:41:36.568+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:41:36.567+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:41:36.597+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:41:36.597+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:41:36.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.392 seconds
[2024-04-30T09:42:06.914+0000] {processor.py:161} INFO - Started process (PID=7458) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:42:06.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:42:06.918+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:42:06.917+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:42:09.235+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:42:09.265+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:42:09.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:42:09.290+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:42:09.290+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:42:09.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.405 seconds
[2024-04-30T09:42:39.552+0000] {processor.py:161} INFO - Started process (PID=7504) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:42:39.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:42:39.555+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:42:39.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:42:41.874+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:42:41.901+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:42:41.901+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:42:41.923+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:42:41.923+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:42:41.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.398 seconds
[2024-04-30T09:43:12.141+0000] {processor.py:161} INFO - Started process (PID=7550) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:43:12.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:43:12.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:43:12.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:43:14.444+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:43:14.468+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:43:14.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:43:14.491+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:43:14.490+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:43:14.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.377 seconds
[2024-04-30T09:43:44.729+0000] {processor.py:161} INFO - Started process (PID=7596) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:43:44.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:43:44.732+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:43:44.732+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:43:47.091+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:43:47.115+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:43:47.114+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:43:47.137+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:43:47.137+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:43:47.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.435 seconds
[2024-04-30T09:44:17.372+0000] {processor.py:161} INFO - Started process (PID=7642) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:44:17.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:44:17.375+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:44:17.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:44:19.740+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:44:19.764+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:44:19.764+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:44:19.788+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:44:19.788+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:44:19.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.443 seconds
[2024-04-30T09:44:50.008+0000] {processor.py:161} INFO - Started process (PID=7688) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:44:50.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:44:50.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:44:50.011+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:44:52.314+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:44:52.338+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:44:52.337+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:44:52.359+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:44:52.359+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:44:52.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.377 seconds
[2024-04-30T09:45:22.606+0000] {processor.py:161} INFO - Started process (PID=7734) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:45:22.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:45:22.609+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:45:22.609+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:45:24.935+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:45:24.960+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:45:24.960+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:45:24.982+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:45:24.982+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:45:25.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.401 seconds
[2024-04-30T09:45:55.252+0000] {processor.py:161} INFO - Started process (PID=7780) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:45:55.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:45:55.256+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:45:55.255+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:45:57.650+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:45:57.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:45:57.673+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:45:57.695+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:45:57.695+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:45:57.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.469 seconds
[2024-04-30T09:46:27.979+0000] {processor.py:161} INFO - Started process (PID=7826) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:46:27.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:46:27.982+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:46:27.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:46:30.339+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:46:30.364+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:46:30.363+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:46:30.389+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:46:30.389+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:46:30.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.438 seconds
[2024-04-30T09:47:00.678+0000] {processor.py:161} INFO - Started process (PID=7872) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:47:00.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:47:00.682+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:47:00.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:47:03.007+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:47:03.032+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:47:03.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:47:03.054+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:47:03.054+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:47:03.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.403 seconds
[2024-04-30T09:47:33.296+0000] {processor.py:161} INFO - Started process (PID=7924) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:47:33.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:47:33.299+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:47:33.299+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:47:35.606+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:47:35.630+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:47:35.630+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:47:35.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:47:35.651+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:47:35.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.383 seconds
[2024-04-30T09:48:05.973+0000] {processor.py:161} INFO - Started process (PID=7970) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:48:05.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:48:05.977+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:48:05.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:48:08.346+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:48:08.371+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:48:08.371+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:48:08.395+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:48:08.394+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:48:08.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.448 seconds
[2024-04-30T09:48:38.745+0000] {processor.py:161} INFO - Started process (PID=8016) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:48:38.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:48:38.748+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:48:38.748+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:48:41.169+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:48:41.193+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:48:41.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:48:41.214+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:48:41.214+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:48:41.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.494 seconds
[2024-04-30T09:49:11.305+0000] {processor.py:161} INFO - Started process (PID=8068) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:49:11.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:49:11.309+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:49:11.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:49:13.601+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:49:13.625+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:49:13.625+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:49:13.650+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:49:13.650+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:49:13.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.372 seconds
[2024-04-30T09:49:43.882+0000] {processor.py:161} INFO - Started process (PID=8114) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:49:43.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:49:43.885+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:49:43.885+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:49:46.213+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:49:46.237+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:49:46.236+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:49:46.257+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:49:46.257+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:49:46.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.402 seconds
[2024-04-30T09:50:16.476+0000] {processor.py:161} INFO - Started process (PID=8160) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:50:16.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:50:16.479+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:50:16.479+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:50:18.841+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:50:18.864+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:50:18.864+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:50:18.886+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:50:18.886+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:50:18.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.436 seconds
[2024-04-30T09:50:49.166+0000] {processor.py:161} INFO - Started process (PID=8206) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:50:49.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:50:49.169+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:50:49.169+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:50:51.533+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:50:51.557+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:50:51.556+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:50:51.579+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:50:51.578+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:50:51.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.440 seconds
[2024-04-30T09:51:21.863+0000] {processor.py:161} INFO - Started process (PID=8252) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:51:21.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:51:21.866+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:51:21.866+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:51:24.156+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:51:24.180+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:51:24.180+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:51:24.201+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:51:24.201+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:51:24.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.367 seconds
[2024-04-30T09:51:54.506+0000] {processor.py:161} INFO - Started process (PID=8299) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:51:54.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:51:54.509+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:51:54.509+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:51:56.811+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:51:56.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:51:56.835+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:51:56.860+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:51:56.860+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:51:56.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.381 seconds
[2024-04-30T09:52:27.158+0000] {processor.py:161} INFO - Started process (PID=8345) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:52:27.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:52:27.162+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:52:27.162+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:52:29.506+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:52:29.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:52:29.531+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:52:29.554+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:52:29.554+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:52:29.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.424 seconds
[2024-04-30T09:52:59.811+0000] {processor.py:161} INFO - Started process (PID=8391) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:52:59.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:52:59.815+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:52:59.814+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:53:02.186+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:53:02.209+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:53:02.208+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:53:02.231+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:53:02.231+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:53:02.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.448 seconds
[2024-04-30T09:53:32.413+0000] {processor.py:161} INFO - Started process (PID=8438) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:53:32.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:53:32.417+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:53:32.416+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:53:34.772+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:53:34.797+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:53:34.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:53:34.818+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:53:34.818+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:53:34.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.429 seconds
[2024-04-30T09:54:05.033+0000] {processor.py:161} INFO - Started process (PID=8490) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:54:05.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:54:05.037+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:54:05.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:54:07.378+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:54:07.401+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:54:07.401+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:54:07.426+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:54:07.425+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:54:07.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.417 seconds
[2024-04-30T09:54:37.685+0000] {processor.py:161} INFO - Started process (PID=8536) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:54:37.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:54:37.688+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:54:37.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:54:40.045+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:54:40.077+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:54:40.077+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:54:40.101+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:54:40.101+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:54:40.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.443 seconds
[2024-04-30T09:55:10.325+0000] {processor.py:161} INFO - Started process (PID=8582) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:55:10.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:55:10.329+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:10.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:55:12.663+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:55:12.688+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:12.687+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:55:12.711+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:12.711+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:55:12.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.412 seconds
[2024-04-30T09:55:42.904+0000] {processor.py:161} INFO - Started process (PID=8628) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:55:42.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:55:42.908+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:42.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:55:45.212+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:55:45.235+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:45.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:55:45.258+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:45.257+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:55:45.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.383 seconds
[2024-04-30T09:56:15.544+0000] {processor.py:161} INFO - Started process (PID=8674) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:56:15.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:56:15.548+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:15.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:56:17.970+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:56:17.996+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:17.996+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:56:18.019+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:18.019+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:56:18.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.502 seconds
[2024-04-30T09:56:48.249+0000] {processor.py:161} INFO - Started process (PID=8720) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:56:48.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:56:48.253+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:48.252+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:56:50.695+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:56:50.717+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:50.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:56:50.739+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:50.739+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:56:50.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.515 seconds
[2024-04-30T09:57:20.895+0000] {processor.py:161} INFO - Started process (PID=8770) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:57:20.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:57:20.898+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:20.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:57:23.222+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:57:23.245+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:23.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:57:23.268+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:23.268+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:57:23.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.400 seconds
[2024-04-30T09:57:53.471+0000] {processor.py:161} INFO - Started process (PID=8818) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:57:53.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:57:53.474+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:53.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:57:55.936+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:57:55.960+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:55.960+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:57:55.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:55.983+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:57:56.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.538 seconds
[2024-04-30T09:58:26.205+0000] {processor.py:161} INFO - Started process (PID=8864) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:58:26.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:58:26.208+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:58:26.208+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:58:28.573+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:58:28.596+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:58:28.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:58:28.618+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:58:28.617+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:58:28.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.439 seconds
[2024-04-30T09:58:58.834+0000] {processor.py:161} INFO - Started process (PID=8910) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:58:58.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:58:58.837+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:58:58.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:59:01.180+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:59:01.204+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:01.203+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:59:01.226+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:01.226+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:59:01.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.420 seconds
[2024-04-30T09:59:31.473+0000] {processor.py:161} INFO - Started process (PID=8956) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:59:31.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T09:59:31.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:31.476+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:59:33.751+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T09:59:33.778+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:33.778+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T09:59:33.801+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:33.800+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T09:59:33.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.354 seconds
[2024-04-30T10:00:04.063+0000] {processor.py:161} INFO - Started process (PID=9008) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:00:04.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:00:04.066+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:04.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:00:06.553+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:00:06.576+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:06.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:00:06.596+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:06.596+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:00:06.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.560 seconds
[2024-04-30T10:00:36.878+0000] {processor.py:161} INFO - Started process (PID=9054) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:00:36.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:00:36.881+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:36.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:00:39.265+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:00:39.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:39.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:00:39.309+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:39.308+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:00:39.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.457 seconds
[2024-04-30T10:01:09.510+0000] {processor.py:161} INFO - Started process (PID=9100) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:01:09.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:01:09.513+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:09.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:01:11.941+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:01:11.964+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:11.964+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:01:11.987+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:11.987+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:01:12.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.501 seconds
[2024-04-30T10:01:42.274+0000] {processor.py:161} INFO - Started process (PID=9146) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:01:42.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:01:42.277+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:42.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:01:44.570+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:01:44.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:44.593+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:01:44.615+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:44.615+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:01:44.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.369 seconds
[2024-04-30T10:02:14.870+0000] {processor.py:161} INFO - Started process (PID=9192) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:02:14.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:02:14.873+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:02:14.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:02:17.181+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:02:17.206+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:02:17.205+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:02:17.228+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:02:17.227+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:02:17.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.383 seconds
[2024-04-30T10:02:47.510+0000] {processor.py:161} INFO - Started process (PID=9238) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:02:47.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:02:47.514+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:02:47.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:02:49.885+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:02:49.910+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:02:49.910+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:02:49.931+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:02:49.931+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:02:49.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.445 seconds
[2024-04-30T10:03:20.279+0000] {processor.py:161} INFO - Started process (PID=9284) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:03:20.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:03:20.283+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:03:20.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:03:22.693+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:03:22.716+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:03:22.715+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:03:22.738+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:03:22.738+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:03:22.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.486 seconds
[2024-04-30T10:03:52.928+0000] {processor.py:161} INFO - Started process (PID=9330) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:03:52.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:03:52.932+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:03:52.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:03:55.274+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:03:55.298+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:03:55.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:03:55.320+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:03:55.320+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:03:55.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.418 seconds
[2024-04-30T10:04:25.511+0000] {processor.py:161} INFO - Started process (PID=9376) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:04:25.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:04:25.515+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:04:25.514+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:04:27.873+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:04:27.900+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:04:27.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:04:27.922+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:04:27.922+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:04:27.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.439 seconds
[2024-04-30T10:04:58.202+0000] {processor.py:161} INFO - Started process (PID=9422) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:04:58.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:04:58.205+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:04:58.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:05:00.591+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:05:00.614+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:05:00.614+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:05:00.636+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:05:00.635+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:05:00.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.461 seconds
[2024-04-30T10:05:30.868+0000] {processor.py:161} INFO - Started process (PID=9468) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:05:30.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:05:30.871+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:05:30.871+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:05:33.204+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:05:33.228+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:05:33.227+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:05:33.250+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:05:33.250+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:05:33.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.409 seconds
[2024-04-30T10:06:03.451+0000] {processor.py:161} INFO - Started process (PID=9520) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:06:03.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:06:03.454+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:06:03.454+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:06:05.746+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:06:05.770+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:06:05.770+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:06:05.793+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:06:05.793+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:06:05.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.367 seconds
[2024-04-30T10:06:36.017+0000] {processor.py:161} INFO - Started process (PID=9572) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:06:36.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:06:36.020+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:06:36.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:06:38.383+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:06:38.407+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:06:38.406+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:06:38.428+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:06:38.428+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:06:38.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.438 seconds
[2024-04-30T10:07:08.708+0000] {processor.py:161} INFO - Started process (PID=9618) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:07:08.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:07:08.712+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:07:08.711+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:07:11.083+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:07:11.106+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:07:11.106+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:07:11.127+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:07:11.127+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:07:11.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.445 seconds
[2024-04-30T10:07:41.285+0000] {processor.py:161} INFO - Started process (PID=9664) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:07:41.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:07:41.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:07:41.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:07:43.584+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:07:43.610+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:07:43.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:07:43.633+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:07:43.633+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:07:43.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.375 seconds
[2024-04-30T10:08:13.871+0000] {processor.py:161} INFO - Started process (PID=9710) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:08:13.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:08:13.876+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:08:13.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:08:16.481+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:08:16.505+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:08:16.505+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:08:16.526+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:08:16.525+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:08:16.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.681 seconds
[2024-04-30T10:08:46.815+0000] {processor.py:161} INFO - Started process (PID=9756) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:08:46.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:08:46.819+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:08:46.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:08:49.158+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:08:49.182+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:08:49.182+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:08:49.204+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:08:49.204+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:08:49.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.415 seconds
[2024-04-30T10:09:19.465+0000] {processor.py:161} INFO - Started process (PID=9802) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:09:19.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:09:19.468+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:09:19.468+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:09:21.871+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:09:21.894+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:09:21.894+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:09:21.915+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:09:21.915+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:09:21.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.476 seconds
[2024-04-30T10:09:52.042+0000] {processor.py:161} INFO - Started process (PID=9848) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:09:52.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:09:52.045+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:09:52.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:09:54.345+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:09:54.368+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:09:54.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:09:54.394+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:09:54.394+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:09:54.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.380 seconds
[2024-04-30T10:10:24.636+0000] {processor.py:161} INFO - Started process (PID=9894) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:10:24.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:10:24.640+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:10:24.639+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:10:26.950+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:10:26.973+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:10:26.973+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:10:26.995+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:10:26.995+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:10:27.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.386 seconds
[2024-04-30T10:10:57.285+0000] {processor.py:161} INFO - Started process (PID=9940) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:10:57.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:10:57.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:10:57.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:10:59.614+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:10:59.638+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:10:59.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:10:59.661+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:10:59.660+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:10:59.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.402 seconds
[2024-04-30T10:11:29.953+0000] {processor.py:161} INFO - Started process (PID=9986) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:11:29.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:11:29.956+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:11:29.955+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:11:32.335+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:11:32.358+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:11:32.357+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:11:32.378+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:11:32.378+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:11:32.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.451 seconds
[2024-04-30T10:12:02.670+0000] {processor.py:161} INFO - Started process (PID=10032) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:12:02.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:12:02.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:12:02.673+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:12:05.054+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:12:05.078+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:12:05.077+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:12:05.099+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:12:05.099+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:12:05.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.458 seconds
[2024-04-30T10:12:35.379+0000] {processor.py:161} INFO - Started process (PID=10084) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:12:35.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:12:35.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:12:35.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:12:37.709+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:12:37.733+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:12:37.733+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:12:37.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:12:37.756+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:12:37.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.404 seconds
[2024-04-30T10:13:08.012+0000] {processor.py:161} INFO - Started process (PID=10130) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:13:08.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:13:08.015+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:13:08.015+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:13:10.342+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:13:10.368+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:13:10.367+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:13:10.390+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:13:10.389+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:13:10.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.406 seconds
[2024-04-30T10:13:40.746+0000] {processor.py:161} INFO - Started process (PID=10176) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:13:40.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:13:40.749+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:13:40.749+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:13:43.154+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:13:43.178+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:13:43.177+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:13:43.199+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:13:43.199+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:13:43.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.478 seconds
[2024-04-30T10:14:13.331+0000] {processor.py:161} INFO - Started process (PID=10225) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:14:13.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:14:13.335+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:14:13.334+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:14:15.644+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:14:15.668+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:14:15.667+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:14:15.689+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:14:15.689+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:14:15.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.383 seconds
[2024-04-30T10:14:46.019+0000] {processor.py:161} INFO - Started process (PID=10274) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:14:46.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:14:46.022+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:14:46.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:14:48.364+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:14:48.395+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:14:48.394+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:14:48.430+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:14:48.430+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:14:48.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.445 seconds
[2024-04-30T10:15:18.712+0000] {processor.py:161} INFO - Started process (PID=10320) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:15:18.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:15:18.715+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:15:18.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:15:21.060+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:15:21.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:15:21.090+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:15:21.116+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:15:21.116+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:15:21.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.437 seconds
[2024-04-30T10:15:51.407+0000] {processor.py:161} INFO - Started process (PID=10366) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:15:51.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:15:51.411+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:15:51.410+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:15:53.720+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:15:53.743+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:15:53.743+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:15:53.766+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:15:53.766+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:15:53.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.386 seconds
[2024-04-30T10:16:23.982+0000] {processor.py:161} INFO - Started process (PID=10412) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:16:23.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:16:23.985+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:16:23.985+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:16:26.310+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:16:26.335+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:16:26.335+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:16:26.357+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:16:26.357+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:16:26.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.402 seconds
[2024-04-30T10:16:56.568+0000] {processor.py:161} INFO - Started process (PID=10458) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:16:56.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:16:56.571+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:16:56.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:16:58.906+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:16:58.930+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:16:58.929+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:16:58.953+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:16:58.953+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:16:58.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.411 seconds
[2024-04-30T10:17:29.153+0000] {processor.py:161} INFO - Started process (PID=10504) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:17:29.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:17:29.156+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:17:29.156+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:17:31.532+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:17:31.555+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:17:31.555+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:17:31.576+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:17:31.576+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:17:31.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.449 seconds
[2024-04-30T10:18:01.723+0000] {processor.py:161} INFO - Started process (PID=10550) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:18:01.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:18:01.727+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:01.726+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:18:04.037+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:18:04.060+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:04.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:18:04.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:04.082+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:18:04.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.386 seconds
[2024-04-30T10:18:34.330+0000] {processor.py:161} INFO - Started process (PID=10597) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:18:34.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:18:34.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:34.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:18:36.716+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:18:36.739+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:36.739+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:18:36.761+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:36.760+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:18:36.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.458 seconds
[2024-04-30T10:19:06.972+0000] {processor.py:161} INFO - Started process (PID=10649) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:19:06.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:19:06.975+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:06.975+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:19:09.314+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:19:09.338+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:09.337+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:19:09.361+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:09.361+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:19:09.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.417 seconds
[2024-04-30T10:19:39.624+0000] {processor.py:161} INFO - Started process (PID=10695) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:19:39.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:19:39.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:39.627+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:19:41.958+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:19:41.982+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:41.982+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:19:42.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:42.003+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:19:42.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.406 seconds
[2024-04-30T10:20:12.192+0000] {processor.py:161} INFO - Started process (PID=10741) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:20:12.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:20:12.195+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:12.195+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:20:14.501+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:20:14.524+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:14.524+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:20:14.548+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:14.547+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:20:14.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.382 seconds
[2024-04-30T10:20:44.831+0000] {processor.py:161} INFO - Started process (PID=10787) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:20:44.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:20:44.835+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:44.834+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:20:47.126+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:20:47.151+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:47.151+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:20:47.175+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:47.175+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:20:47.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.372 seconds
[2024-04-30T10:21:17.453+0000] {processor.py:161} INFO - Started process (PID=10833) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:21:17.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:21:17.457+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:17.456+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:21:19.815+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:21:19.838+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:19.838+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:21:19.859+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:19.859+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:21:19.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.433 seconds
[2024-04-30T10:21:50.093+0000] {processor.py:161} INFO - Started process (PID=10879) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:21:50.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:21:50.096+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:50.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:21:52.471+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:21:52.495+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:52.494+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:21:52.515+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:52.514+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:21:52.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.449 seconds
[2024-04-30T10:22:22.721+0000] {processor.py:161} INFO - Started process (PID=10925) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:22:22.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:22:22.724+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:22.724+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:22:25.075+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:22:25.098+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:25.097+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:22:25.120+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:25.119+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:22:25.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.425 seconds
[2024-04-30T10:22:55.331+0000] {processor.py:161} INFO - Started process (PID=10977) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:22:55.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:22:55.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:55.334+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:22:57.633+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:22:57.657+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:57.657+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:22:57.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:57.684+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:22:57.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.380 seconds
[2024-04-30T10:23:28.056+0000] {processor.py:161} INFO - Started process (PID=11023) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:23:28.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:23:28.059+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:28.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:23:30.450+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:23:30.474+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:30.473+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:23:30.494+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:30.494+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:23:30.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.462 seconds
[2024-04-30T10:24:00.765+0000] {processor.py:161} INFO - Started process (PID=11069) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:24:00.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:24:00.769+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:00.768+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:24:03.131+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:24:03.154+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:03.154+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:24:03.176+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:03.175+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:24:03.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.437 seconds
[2024-04-30T10:24:33.329+0000] {processor.py:161} INFO - Started process (PID=11115) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:24:33.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:24:33.332+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:33.332+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:24:35.620+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:24:35.645+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:35.645+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:24:35.667+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:35.667+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:24:35.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.365 seconds
[2024-04-30T10:25:05.947+0000] {processor.py:161} INFO - Started process (PID=11167) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:25:05.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:25:05.951+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:05.950+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:25:08.257+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:25:08.281+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:08.281+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:25:08.303+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:08.303+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:25:08.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.382 seconds
[2024-04-30T10:25:38.585+0000] {processor.py:161} INFO - Started process (PID=11213) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:25:38.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:25:38.589+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:38.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:25:40.949+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:25:40.973+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:40.973+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:25:40.994+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:40.994+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:25:41.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.435 seconds
[2024-04-30T10:26:11.240+0000] {processor.py:161} INFO - Started process (PID=11259) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:26:11.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:26:11.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:11.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:26:13.560+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:26:13.584+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:13.584+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:26:13.605+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:13.605+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:26:13.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.390 seconds
[2024-04-30T10:26:43.833+0000] {processor.py:161} INFO - Started process (PID=11305) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:26:43.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:26:43.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:43.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:26:46.109+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:26:46.132+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:46.131+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:26:46.153+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:46.153+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:26:46.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.347 seconds
[2024-04-30T10:27:16.417+0000] {processor.py:161} INFO - Started process (PID=11351) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:27:16.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:27:16.420+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:16.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:27:18.734+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:27:18.759+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:18.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:27:18.781+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:18.781+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:27:18.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.391 seconds
[2024-04-30T10:27:49.078+0000] {processor.py:161} INFO - Started process (PID=11397) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:27:49.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:27:49.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:49.081+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:27:51.381+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:27:51.404+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:51.404+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:27:51.428+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:51.427+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:27:51.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.378 seconds
[2024-04-30T10:28:21.716+0000] {processor.py:161} INFO - Started process (PID=11443) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:28:21.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:28:21.720+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:21.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:28:23.995+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:28:24.018+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:24.018+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:28:24.041+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:24.040+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:28:24.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.351 seconds
[2024-04-30T10:28:54.270+0000] {processor.py:161} INFO - Started process (PID=11489) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:28:54.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:28:54.273+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:54.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:28:56.558+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:28:56.581+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:56.580+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:28:56.603+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:56.603+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:28:56.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.360 seconds
[2024-04-30T10:29:26.848+0000] {processor.py:161} INFO - Started process (PID=11535) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:29:26.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:29:26.852+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:29:26.851+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:29:29.233+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:29:29.257+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:29:29.257+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:29:29.279+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:29:29.279+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:29:29.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.456 seconds
[2024-04-30T10:29:59.510+0000] {processor.py:161} INFO - Started process (PID=11581) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:29:59.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:29:59.514+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:29:59.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:30:01.847+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:30:01.879+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:30:01.878+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:30:01.906+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:30:01.906+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:30:01.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.425 seconds
[2024-04-30T10:30:32.236+0000] {processor.py:161} INFO - Started process (PID=11627) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:30:32.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:30:32.239+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:30:32.239+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:30:34.608+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:30:34.633+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:30:34.632+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:30:34.654+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:30:34.654+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:30:34.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.443 seconds
[2024-04-30T10:31:04.859+0000] {processor.py:161} INFO - Started process (PID=11677) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:31:04.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:31:04.863+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:31:04.862+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:31:07.178+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:31:07.200+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:31:07.200+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:31:07.220+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:31:07.220+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:31:07.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.388 seconds
[2024-04-30T10:31:37.500+0000] {processor.py:161} INFO - Started process (PID=11731) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:31:37.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:31:37.503+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:31:37.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:31:39.863+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:31:39.887+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:31:39.886+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:31:39.909+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:31:39.908+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:31:39.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.438 seconds
[2024-04-30T10:32:10.080+0000] {processor.py:161} INFO - Started process (PID=11777) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:32:10.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:32:10.084+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:32:10.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:32:12.429+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:32:12.456+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:32:12.455+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:32:12.480+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:32:12.480+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:32:12.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.426 seconds
[2024-04-30T10:32:42.756+0000] {processor.py:161} INFO - Started process (PID=11823) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:32:42.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:32:42.759+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:32:42.759+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:32:45.044+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:32:45.070+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:32:45.069+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:32:45.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:32:45.091+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:32:45.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.362 seconds
[2024-04-30T10:33:15.370+0000] {processor.py:161} INFO - Started process (PID=11870) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:33:15.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:33:15.374+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:33:15.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:33:17.660+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:33:17.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:33:17.683+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:33:17.705+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:33:17.705+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:33:17.724+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.361 seconds
[2024-04-30T10:33:47.998+0000] {processor.py:161} INFO - Started process (PID=11916) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:33:48.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:33:48.002+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:33:48.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:33:50.385+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:33:50.409+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:33:50.408+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:33:50.430+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:33:50.430+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:33:50.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.457 seconds
[2024-04-30T10:34:20.710+0000] {processor.py:161} INFO - Started process (PID=11962) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:34:20.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:34:20.713+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:34:20.713+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:34:23.087+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:34:23.109+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:34:23.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:34:23.131+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:34:23.131+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:34:23.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.447 seconds
[2024-04-30T10:34:53.415+0000] {processor.py:161} INFO - Started process (PID=12008) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:34:53.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:34:53.418+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:34:53.418+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:34:55.713+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:34:55.739+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:34:55.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:34:55.760+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:34:55.760+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:34:55.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.371 seconds
[2024-04-30T10:35:26.007+0000] {processor.py:161} INFO - Started process (PID=12054) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:35:26.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:35:26.010+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:35:26.010+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:35:28.322+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:35:28.344+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:35:28.344+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:35:28.365+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:35:28.365+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:35:28.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.384 seconds
[2024-04-30T10:35:58.644+0000] {processor.py:161} INFO - Started process (PID=12100) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:35:58.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:35:58.647+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:35:58.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:36:01.037+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:36:01.060+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:36:01.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:36:01.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:36:01.082+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:36:01.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.464 seconds
[2024-04-30T10:36:31.363+0000] {processor.py:161} INFO - Started process (PID=12146) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:36:31.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:36:31.367+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:36:31.366+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:36:33.688+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:36:33.712+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:36:33.712+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:36:33.734+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:36:33.734+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:36:33.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.399 seconds
[2024-04-30T10:37:04.025+0000] {processor.py:161} INFO - Started process (PID=12192) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:37:04.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:37:04.029+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:37:04.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:37:06.309+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:37:06.333+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:37:06.333+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:37:06.354+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:37:06.354+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:37:06.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.354 seconds
[2024-04-30T10:37:36.610+0000] {processor.py:161} INFO - Started process (PID=12244) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:37:36.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:37:36.613+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:37:36.613+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:37:38.941+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:37:38.964+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:37:38.964+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:37:38.987+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:37:38.986+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:37:39.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.402 seconds
[2024-04-30T10:38:09.265+0000] {processor.py:161} INFO - Started process (PID=12290) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:38:09.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:38:09.269+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:38:09.269+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:38:11.608+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:38:11.632+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:38:11.632+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:38:11.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:38:11.655+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:38:11.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.415 seconds
[2024-04-30T10:38:41.997+0000] {processor.py:161} INFO - Started process (PID=12336) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:38:41.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:38:42.000+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:38:42.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:38:44.325+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:38:44.348+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:38:44.348+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:38:44.371+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:38:44.371+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:38:44.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.404 seconds
[2024-04-30T10:39:14.651+0000] {processor.py:161} INFO - Started process (PID=12382) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:39:14.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:39:14.654+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:39:14.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:39:17.016+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:39:17.041+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:39:17.040+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:39:17.066+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:39:17.066+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:39:17.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.441 seconds
[2024-04-30T10:39:47.383+0000] {processor.py:161} INFO - Started process (PID=12434) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:39:47.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:39:47.386+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:39:47.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:39:49.739+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:39:49.762+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:39:49.762+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:39:49.784+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:39:49.784+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:39:49.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.427 seconds
[2024-04-30T10:40:20.057+0000] {processor.py:161} INFO - Started process (PID=12480) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:40:20.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:40:20.061+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:40:20.060+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:40:22.454+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:40:22.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:40:22.477+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:40:22.499+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:40:22.498+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:40:22.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.468 seconds
[2024-04-30T10:40:52.782+0000] {processor.py:161} INFO - Started process (PID=12526) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:40:52.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:40:52.785+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:40:52.785+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:40:55.110+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:40:55.134+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:40:55.134+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:40:55.157+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:40:55.157+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:40:55.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.401 seconds
[2024-04-30T10:41:25.437+0000] {processor.py:161} INFO - Started process (PID=12572) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:41:25.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:41:25.440+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:41:25.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:41:27.727+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:41:27.754+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:41:27.753+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:41:27.775+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:41:27.774+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:41:27.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.364 seconds
[2024-04-30T10:41:58.072+0000] {processor.py:161} INFO - Started process (PID=12618) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:41:58.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:41:58.076+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:41:58.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:42:00.448+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:42:00.472+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:42:00.471+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:42:00.492+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:42:00.492+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:42:00.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.447 seconds
[2024-04-30T10:42:30.708+0000] {processor.py:161} INFO - Started process (PID=12664) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:42:30.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:42:30.712+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:42:30.711+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:42:33.086+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:42:33.109+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:42:33.109+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:42:33.131+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:42:33.131+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:42:33.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.449 seconds
[2024-04-30T10:43:03.296+0000] {processor.py:161} INFO - Started process (PID=12710) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:43:03.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:43:03.299+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:43:03.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:43:05.563+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:43:05.586+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:43:05.586+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:43:05.608+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:43:05.608+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:43:05.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.339 seconds
[2024-04-30T10:43:36.016+0000] {processor.py:161} INFO - Started process (PID=12756) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:43:36.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:43:36.019+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:43:36.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:43:38.353+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:43:38.378+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:43:38.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:43:38.400+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:43:38.399+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:43:38.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.414 seconds
[2024-04-30T10:44:08.682+0000] {processor.py:161} INFO - Started process (PID=12808) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:44:08.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:44:08.685+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:44:08.685+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:44:11.108+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:44:11.131+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:44:11.130+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:44:11.150+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:44:11.150+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:44:11.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.495 seconds
[2024-04-30T10:44:41.440+0000] {processor.py:161} INFO - Started process (PID=12854) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:44:41.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:44:41.443+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:44:41.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:44:43.762+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:44:43.786+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:44:43.785+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:44:43.809+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:44:43.809+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:44:43.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.396 seconds
[2024-04-30T10:45:14.098+0000] {processor.py:161} INFO - Started process (PID=12900) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:45:14.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:45:14.101+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:45:14.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:45:16.397+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:45:16.421+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:45:16.421+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:45:16.443+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:45:16.443+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:45:16.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.371 seconds
[2024-04-30T10:45:46.677+0000] {processor.py:161} INFO - Started process (PID=12946) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:45:46.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:45:46.680+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:45:46.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:45:48.967+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:45:48.992+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:45:48.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:45:49.014+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:45:49.013+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:45:49.033+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.363 seconds
[2024-04-30T10:46:19.314+0000] {processor.py:161} INFO - Started process (PID=12992) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:46:19.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:46:19.318+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:46:19.317+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:46:21.675+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:46:21.697+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:46:21.697+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:46:21.718+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:46:21.718+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:46:21.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.431 seconds
[2024-04-30T10:46:51.974+0000] {processor.py:161} INFO - Started process (PID=13038) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:46:51.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:46:51.977+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:46:51.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:46:54.362+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:46:54.384+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:46:54.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:46:54.406+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:46:54.406+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:46:54.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.462 seconds
[2024-04-30T10:47:24.570+0000] {processor.py:161} INFO - Started process (PID=13084) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:47:24.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:47:24.573+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:47:24.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:47:26.938+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:47:26.961+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:47:26.961+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:47:26.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:47:26.982+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:47:26.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.436 seconds
[2024-04-30T10:47:57.289+0000] {processor.py:161} INFO - Started process (PID=13133) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:47:57.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:47:57.292+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:47:57.292+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:47:59.605+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:47:59.630+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:47:59.629+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:47:59.651+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:47:59.651+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:47:59.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.387 seconds
[2024-04-30T10:48:30.074+0000] {processor.py:161} INFO - Started process (PID=13182) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:48:30.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:48:30.078+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:48:30.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:48:32.373+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:48:32.399+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:48:32.398+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:48:32.419+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:48:32.419+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:48:32.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.371 seconds
[2024-04-30T10:49:02.691+0000] {processor.py:161} INFO - Started process (PID=13228) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:49:02.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:49:02.695+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:49:02.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:49:05.047+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:49:05.069+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:49:05.069+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:49:05.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:49:05.091+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:49:05.108+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.425 seconds
[2024-04-30T10:49:35.313+0000] {processor.py:161} INFO - Started process (PID=13274) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:49:35.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:49:35.317+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:49:35.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:49:37.610+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:49:37.634+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:49:37.633+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:49:37.657+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:49:37.657+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:49:37.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.371 seconds
[2024-04-30T10:50:07.902+0000] {processor.py:161} INFO - Started process (PID=13326) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:50:07.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:50:07.905+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:50:07.905+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:50:10.259+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:50:10.283+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:50:10.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:50:10.305+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:50:10.304+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:50:10.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.430 seconds
[2024-04-30T10:50:40.533+0000] {processor.py:161} INFO - Started process (PID=13372) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:50:40.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:50:40.536+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:50:40.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:50:42.864+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:50:42.889+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:50:42.889+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:50:42.913+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:50:42.912+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:50:42.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.414 seconds
[2024-04-30T10:51:13.152+0000] {processor.py:161} INFO - Started process (PID=13418) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:51:13.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:51:13.155+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:51:13.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:51:15.484+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:51:15.508+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:51:15.507+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:51:15.530+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:51:15.530+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:51:15.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.404 seconds
[2024-04-30T10:51:45.722+0000] {processor.py:161} INFO - Started process (PID=13464) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:51:45.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:51:45.725+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:51:45.725+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:51:47.996+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:51:48.019+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:51:48.018+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:51:48.041+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:51:48.041+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:51:48.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.346 seconds
[2024-04-30T10:52:18.278+0000] {processor.py:161} INFO - Started process (PID=13510) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:52:18.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:52:18.281+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:52:18.281+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:52:20.619+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:52:20.644+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:52:20.643+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:52:20.664+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:52:20.664+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:52:20.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.412 seconds
[2024-04-30T10:52:50.871+0000] {processor.py:161} INFO - Started process (PID=13556) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:52:50.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:52:50.875+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:52:50.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:52:53.187+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:52:53.211+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:52:53.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:52:53.232+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:52:53.232+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:52:53.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.385 seconds
[2024-04-30T10:53:23.476+0000] {processor.py:161} INFO - Started process (PID=13602) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:53:23.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:53:23.480+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:53:23.479+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:53:25.767+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:53:25.789+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:53:25.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:53:25.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:53:25.810+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:53:25.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.360 seconds
[2024-04-30T10:53:56.054+0000] {processor.py:161} INFO - Started process (PID=13648) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:53:56.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:53:56.057+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:53:56.057+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:53:58.390+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:53:58.416+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:53:58.415+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:53:58.438+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:53:58.438+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:53:58.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.411 seconds
[2024-04-30T10:54:28.694+0000] {processor.py:161} INFO - Started process (PID=13694) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:54:28.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:54:28.698+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:54:28.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:54:31.091+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:54:31.116+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:54:31.115+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:54:31.137+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:54:31.137+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:54:31.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.469 seconds
[2024-04-30T10:55:01.330+0000] {processor.py:161} INFO - Started process (PID=13740) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:55:01.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:55:01.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:55:01.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:55:03.664+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:55:03.686+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:55:03.685+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:55:03.707+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:55:03.706+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:55:03.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.401 seconds
[2024-04-30T10:55:33.900+0000] {processor.py:161} INFO - Started process (PID=13786) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:55:33.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:55:33.903+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:55:33.903+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:55:36.204+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:55:36.227+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:55:36.227+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:55:36.248+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:55:36.248+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:55:36.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.375 seconds
[2024-04-30T10:56:06.524+0000] {processor.py:161} INFO - Started process (PID=13832) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:56:06.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:56:06.528+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:56:06.528+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:56:08.919+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:56:08.942+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:56:08.942+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:56:08.963+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:56:08.963+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:56:08.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.465 seconds
[2024-04-30T10:56:39.183+0000] {processor.py:161} INFO - Started process (PID=13890) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:56:39.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:56:39.187+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:56:39.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:56:41.566+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:56:41.590+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:56:41.589+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:56:41.610+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:56:41.610+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:56:41.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.453 seconds
[2024-04-30T10:57:11.794+0000] {processor.py:161} INFO - Started process (PID=13936) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:57:11.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:57:11.797+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:57:11.797+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:57:14.146+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:57:14.170+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:57:14.169+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:57:14.191+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:57:14.191+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:57:14.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.423 seconds
[2024-04-30T10:57:44.334+0000] {processor.py:161} INFO - Started process (PID=13982) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:57:44.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:57:44.337+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:57:44.337+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:57:46.621+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:57:46.643+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:57:46.643+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:57:46.665+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:57:46.665+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:57:46.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.355 seconds
[2024-04-30T10:58:16.917+0000] {processor.py:161} INFO - Started process (PID=14028) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:58:16.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:58:16.920+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:58:16.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:58:19.206+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:58:19.231+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:58:19.230+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:58:19.253+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:58:19.253+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:58:19.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.362 seconds
[2024-04-30T10:58:49.556+0000] {processor.py:161} INFO - Started process (PID=14074) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:58:49.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:58:49.560+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:58:49.559+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:58:51.934+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:58:51.962+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:58:51.961+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:58:51.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:58:51.982+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:58:52.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.453 seconds
[2024-04-30T10:59:22.175+0000] {processor.py:161} INFO - Started process (PID=14120) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:59:22.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:59:22.178+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:59:22.178+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:59:24.527+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:59:24.550+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:59:24.550+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:59:24.572+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:59:24.571+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:59:24.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.423 seconds
[2024-04-30T10:59:54.789+0000] {processor.py:161} INFO - Started process (PID=14166) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:59:54.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T10:59:54.793+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:59:54.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:59:57.070+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T10:59:57.094+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:59:57.093+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:59:57.119+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:59:57.119+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:59:57.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.355 seconds
[2024-04-30T11:00:27.389+0000] {processor.py:161} INFO - Started process (PID=14212) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:00:27.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:00:27.393+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:00:27.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:00:29.684+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:00:29.709+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:00:29.708+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:00:29.730+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:00:29.730+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:00:29.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.367 seconds
[2024-04-30T11:01:00.049+0000] {processor.py:161} INFO - Started process (PID=14258) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:01:00.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:01:00.052+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:01:00.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:01:02.431+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:01:02.455+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:01:02.454+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:01:02.476+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:01:02.476+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:01:02.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.453 seconds
[2024-04-30T11:01:32.669+0000] {processor.py:161} INFO - Started process (PID=14304) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:01:32.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:01:32.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:01:32.672+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:01:35.004+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:01:35.027+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:01:35.026+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:01:35.049+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:01:35.049+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:01:35.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.407 seconds
[2024-04-30T11:02:05.246+0000] {processor.py:161} INFO - Started process (PID=14350) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:02:05.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:02:05.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:02:05.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:02:07.661+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:02:07.685+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:02:07.685+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:02:07.707+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:02:07.707+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:02:07.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.489 seconds
[2024-04-30T11:02:37.927+0000] {processor.py:161} INFO - Started process (PID=14396) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:02:37.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:02:37.931+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:02:37.930+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:02:40.281+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:02:40.306+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:02:40.306+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:02:40.330+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:02:40.329+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:02:40.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.428 seconds
[2024-04-30T11:03:10.584+0000] {processor.py:161} INFO - Started process (PID=14448) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:03:10.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:03:10.588+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:03:10.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:03:12.944+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:03:12.970+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:03:12.969+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:03:12.991+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:03:12.991+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:03:13.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.434 seconds
[2024-04-30T11:03:43.248+0000] {processor.py:161} INFO - Started process (PID=14494) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:03:43.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:03:43.251+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:03:43.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:03:45.595+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:03:45.618+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:03:45.617+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:03:45.638+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:03:45.638+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:03:45.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.418 seconds
[2024-04-30T11:04:15.904+0000] {processor.py:161} INFO - Started process (PID=14540) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:04:15.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:04:15.908+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:04:15.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:04:18.236+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:04:18.259+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:04:18.259+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:04:18.280+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:04:18.280+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:04:18.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.401 seconds
[2024-04-30T11:04:48.510+0000] {processor.py:161} INFO - Started process (PID=14590) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:04:48.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:04:48.513+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:04:48.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:04:50.821+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:04:50.851+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:04:50.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:04:50.880+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:04:50.879+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:04:50.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.402 seconds
[2024-04-30T11:05:21.131+0000] {processor.py:161} INFO - Started process (PID=14638) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:05:21.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:05:21.134+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:05:21.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:05:23.446+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:05:23.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:05:23.477+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:05:23.504+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:05:23.503+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:05:23.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.400 seconds
[2024-04-30T11:05:53.729+0000] {processor.py:161} INFO - Started process (PID=14684) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:05:53.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:05:53.733+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:05:53.732+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:05:56.040+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:05:56.062+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:05:56.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:05:56.084+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:05:56.083+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:05:56.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.380 seconds
[2024-04-30T11:06:26.284+0000] {processor.py:161} INFO - Started process (PID=14730) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:06:26.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:06:26.288+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:06:26.287+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:06:28.651+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:06:28.676+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:06:28.675+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:06:28.698+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:06:28.698+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:06:28.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.440 seconds
[2024-04-30T11:06:58.870+0000] {processor.py:161} INFO - Started process (PID=14776) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:06:58.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:06:58.873+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:06:58.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:07:01.265+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:07:01.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:07:01.289+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:07:01.310+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:07:01.309+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:07:01.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.467 seconds
[2024-04-30T11:07:31.483+0000] {processor.py:161} INFO - Started process (PID=14822) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:07:31.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:07:31.487+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:07:31.486+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:07:33.862+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:07:33.887+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:07:33.887+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:07:33.908+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:07:33.908+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:07:33.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.452 seconds
[2024-04-30T11:08:04.195+0000] {processor.py:161} INFO - Started process (PID=14868) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:08:04.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:08:04.199+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:08:04.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:08:06.549+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:08:06.571+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:08:06.571+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:08:06.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:08:06.593+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:08:06.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.422 seconds
[2024-04-30T11:08:36.873+0000] {processor.py:161} INFO - Started process (PID=14914) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:08:36.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:08:36.877+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:08:36.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:08:39.201+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:08:39.224+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:08:39.223+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:08:39.245+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:08:39.245+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:08:39.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.400 seconds
[2024-04-30T11:09:09.516+0000] {processor.py:161} INFO - Started process (PID=14966) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:09:09.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:09:09.520+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:09:09.519+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:09:11.902+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:09:11.926+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:09:11.926+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:09:11.947+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:09:11.947+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:09:11.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.456 seconds
[2024-04-30T11:09:42.179+0000] {processor.py:161} INFO - Started process (PID=15012) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:09:42.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:09:42.183+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:09:42.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:09:44.507+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:09:44.529+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:09:44.528+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:09:44.550+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:09:44.549+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:09:44.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.397 seconds
[2024-04-30T11:10:14.753+0000] {processor.py:161} INFO - Started process (PID=15058) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:10:14.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:10:14.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:10:14.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:10:17.088+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:10:17.110+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:10:17.110+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:10:17.131+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:10:17.131+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:10:17.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.406 seconds
[2024-04-30T11:10:47.321+0000] {processor.py:161} INFO - Started process (PID=15104) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:10:47.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:10:47.325+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:10:47.324+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:10:49.636+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:10:49.660+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:10:49.659+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:10:49.681+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:10:49.681+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:10:49.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.385 seconds
[2024-04-30T11:11:19.929+0000] {processor.py:161} INFO - Started process (PID=15150) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:11:19.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:11:19.932+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:11:19.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:11:22.284+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:11:22.308+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:11:22.308+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:11:22.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:11:22.333+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:11:22.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.434 seconds
[2024-04-30T11:11:52.618+0000] {processor.py:161} INFO - Started process (PID=15196) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:11:52.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:11:52.622+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:11:52.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:11:54.991+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:11:55.015+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:11:55.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:11:55.036+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:11:55.036+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:11:55.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.446 seconds
[2024-04-30T11:12:25.181+0000] {processor.py:161} INFO - Started process (PID=15242) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:12:25.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:12:25.184+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:12:25.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:12:27.455+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:12:27.479+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:12:27.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:12:27.499+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:12:27.499+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:12:27.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.344 seconds
[2024-04-30T11:12:57.761+0000] {processor.py:161} INFO - Started process (PID=15288) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:12:57.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:12:57.764+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:12:57.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:13:00.144+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:13:00.167+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:13:00.167+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:13:00.189+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:13:00.188+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:13:00.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.454 seconds
[2024-04-30T11:13:30.379+0000] {processor.py:161} INFO - Started process (PID=15340) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:13:30.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:13:30.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:13:30.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:13:32.833+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:13:32.858+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:13:32.857+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:13:32.882+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:13:32.882+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:13:32.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.531 seconds
[2024-04-30T11:14:03.061+0000] {processor.py:161} INFO - Started process (PID=15386) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:14:03.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:14:03.064+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:14:03.064+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:14:05.409+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:14:05.433+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:14:05.432+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:14:05.455+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:14:05.454+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:14:05.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.420 seconds
[2024-04-30T11:14:35.643+0000] {processor.py:161} INFO - Started process (PID=15432) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:14:35.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:14:35.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:14:35.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:14:37.959+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:14:37.982+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:14:37.981+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:14:38.002+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:14:38.001+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:14:38.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.385 seconds
[2024-04-30T11:15:08.233+0000] {processor.py:161} INFO - Started process (PID=15478) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:15:08.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:15:08.236+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:15:08.236+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:15:10.555+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:15:10.578+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:15:10.578+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:15:10.600+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:15:10.600+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:15:10.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.393 seconds
[2024-04-30T11:15:40.867+0000] {processor.py:161} INFO - Started process (PID=15530) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:15:40.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:15:40.871+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:15:40.870+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:15:43.242+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:15:43.266+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:15:43.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:15:43.286+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:15:43.286+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:15:43.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.445 seconds
[2024-04-30T11:16:13.512+0000] {processor.py:161} INFO - Started process (PID=15576) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:16:13.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:16:13.516+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:16:13.515+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:16:15.832+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:16:15.855+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:16:15.854+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:16:15.876+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:16:15.876+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:16:15.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.391 seconds
[2024-04-30T11:16:46.089+0000] {processor.py:161} INFO - Started process (PID=15622) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:16:46.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:16:46.092+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:16:46.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:16:48.352+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:16:48.376+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:16:48.376+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:16:48.399+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:16:48.399+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:16:48.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.337 seconds
[2024-04-30T11:17:18.664+0000] {processor.py:161} INFO - Started process (PID=15668) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:17:18.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:17:18.667+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:17:18.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:17:20.989+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:17:21.013+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:17:21.012+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:17:21.034+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:17:21.034+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:17:21.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.397 seconds
[2024-04-30T11:17:51.286+0000] {processor.py:161} INFO - Started process (PID=15714) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:17:51.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:17:51.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:17:51.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:17:53.646+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:17:53.669+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:17:53.669+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:17:53.690+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:17:53.690+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:17:53.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.430 seconds
[2024-04-30T11:18:23.947+0000] {processor.py:161} INFO - Started process (PID=15760) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:18:23.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:18:23.951+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:18:23.951+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:18:26.300+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:18:26.324+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:18:26.323+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:18:26.345+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:18:26.345+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:18:26.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.425 seconds
[2024-04-30T11:18:56.540+0000] {processor.py:161} INFO - Started process (PID=15806) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:18:56.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:18:56.544+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:18:56.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:18:58.833+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:18:58.857+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:18:58.856+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:18:58.880+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:18:58.879+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:18:58.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.366 seconds
[2024-04-30T11:19:29.118+0000] {processor.py:161} INFO - Started process (PID=15852) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:19:29.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:19:29.121+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:19:29.121+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:19:31.414+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:19:31.437+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:19:31.437+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:19:31.462+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:19:31.462+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:19:31.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.371 seconds
[2024-04-30T11:20:01.748+0000] {processor.py:161} INFO - Started process (PID=15898) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:20:01.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:20:01.752+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:20:01.752+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:20:04.047+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:20:04.071+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:20:04.071+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:20:04.093+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:20:04.092+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:20:04.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.368 seconds
[2024-04-30T11:20:34.368+0000] {processor.py:161} INFO - Started process (PID=15944) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:20:34.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:20:34.374+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:20:34.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:20:36.652+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:20:36.677+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:20:36.677+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:20:36.697+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:20:36.697+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:20:36.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.358 seconds
[2024-04-30T11:21:06.921+0000] {processor.py:161} INFO - Started process (PID=15990) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:21:06.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:21:06.924+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:21:06.924+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:21:09.209+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:21:09.233+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:21:09.233+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:21:09.255+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:21:09.254+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:21:09.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.361 seconds
[2024-04-30T11:21:39.543+0000] {processor.py:161} INFO - Started process (PID=16036) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:21:39.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:21:39.546+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:21:39.545+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:21:41.954+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:21:41.978+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:21:41.977+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:21:41.999+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:21:41.998+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:21:42.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.481 seconds
[2024-04-30T11:22:12.159+0000] {processor.py:161} INFO - Started process (PID=16094) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:22:12.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:22:12.163+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:22:12.162+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:22:14.507+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:22:14.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:22:14.532+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:22:14.561+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:22:14.561+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:22:14.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.433 seconds
[2024-04-30T11:22:44.787+0000] {processor.py:161} INFO - Started process (PID=16140) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:22:44.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:22:44.791+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:22:44.791+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:22:47.139+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:22:47.162+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:22:47.161+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:22:47.182+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:22:47.182+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:22:47.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.422 seconds
[2024-04-30T11:23:17.363+0000] {processor.py:161} INFO - Started process (PID=16186) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:23:17.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:23:17.366+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:23:17.366+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:23:19.666+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:23:19.689+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:23:19.689+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:23:19.710+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:23:19.710+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:23:19.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.375 seconds
[2024-04-30T11:23:50.094+0000] {processor.py:161} INFO - Started process (PID=16232) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:23:50.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:23:50.097+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:23:50.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:23:52.443+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:23:52.465+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:23:52.465+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:23:52.487+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:23:52.486+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:23:52.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.418 seconds
[2024-04-30T11:24:22.757+0000] {processor.py:161} INFO - Started process (PID=16278) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:24:22.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:24:22.761+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:24:22.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:24:25.147+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:24:25.172+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:24:25.172+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:24:25.194+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:24:25.194+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:24:25.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.465 seconds
[2024-04-30T11:24:55.473+0000] {processor.py:161} INFO - Started process (PID=16324) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:24:55.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:24:55.476+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:24:55.476+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:24:57.786+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:24:57.808+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:24:57.808+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:24:57.830+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:24:57.830+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:24:57.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.385 seconds
[2024-04-30T11:25:28.019+0000] {processor.py:161} INFO - Started process (PID=16370) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:25:28.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:25:28.022+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:25:28.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:25:30.315+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:25:30.340+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:25:30.340+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:25:30.361+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:25:30.361+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:25:30.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.369 seconds
[2024-04-30T11:26:00.674+0000] {processor.py:161} INFO - Started process (PID=16416) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:26:00.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:26:00.678+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:26:00.677+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:26:03.072+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:26:03.095+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:26:03.095+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:26:03.118+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:26:03.117+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:26:03.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.470 seconds
[2024-04-30T11:26:33.400+0000] {processor.py:161} INFO - Started process (PID=16462) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:26:33.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:26:33.404+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:26:33.404+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:26:35.741+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:26:35.766+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:26:35.766+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:26:35.790+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:26:35.790+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:26:35.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.418 seconds
[2024-04-30T11:27:06.075+0000] {processor.py:161} INFO - Started process (PID=16508) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:27:06.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:27:06.078+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:27:06.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:27:08.380+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:27:08.403+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:27:08.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:27:08.423+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:27:08.423+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:27:08.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.375 seconds
[2024-04-30T11:27:38.653+0000] {processor.py:161} INFO - Started process (PID=16554) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:27:38.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:27:38.656+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:27:38.656+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:27:40.981+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:27:41.005+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:27:41.004+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:27:41.026+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:27:41.026+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:27:41.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.504 seconds
[2024-04-30T11:28:11.414+0000] {processor.py:161} INFO - Started process (PID=16606) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:28:11.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:28:11.417+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:28:11.417+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:28:13.764+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:28:13.787+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:28:13.787+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:28:13.810+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:28:13.810+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:28:13.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.422 seconds
[2024-04-30T11:28:44.141+0000] {processor.py:161} INFO - Started process (PID=16652) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:28:44.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:28:44.145+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:28:44.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:28:46.516+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:28:46.539+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:28:46.539+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:28:46.561+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:28:46.561+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:28:46.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.447 seconds
[2024-04-30T11:29:16.854+0000] {processor.py:161} INFO - Started process (PID=16698) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:29:16.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:29:16.858+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:29:16.858+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:29:19.171+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:29:19.194+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:29:19.194+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:29:19.216+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:29:19.215+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:29:19.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.387 seconds
[2024-04-30T11:29:49.430+0000] {processor.py:161} INFO - Started process (PID=16744) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:29:49.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:29:49.434+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:29:49.434+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:29:51.776+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:29:51.800+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:29:51.799+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:29:51.820+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:29:51.820+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:29:51.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.418 seconds
[2024-04-30T11:30:22.093+0000] {processor.py:161} INFO - Started process (PID=16794) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:30:22.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:30:22.098+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:30:22.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:30:24.452+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:30:24.476+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:30:24.476+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:30:24.498+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:30:24.497+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:30:24.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.435 seconds
[2024-04-30T11:30:54.724+0000] {processor.py:161} INFO - Started process (PID=16842) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:30:54.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:30:54.727+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:30:54.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:30:57.049+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:30:57.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:30:57.072+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:30:57.092+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:30:57.092+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:30:57.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.394 seconds
[2024-04-30T11:31:27.298+0000] {processor.py:161} INFO - Started process (PID=16888) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:31:27.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:31:27.301+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:31:27.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:31:29.614+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:31:29.636+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:31:29.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:31:29.656+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:31:29.656+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:31:29.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.384 seconds
[2024-04-30T11:31:59.900+0000] {processor.py:161} INFO - Started process (PID=16934) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:31:59.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:31:59.903+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:31:59.903+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:32:02.223+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:32:02.251+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:32:02.251+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:32:02.278+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:32:02.277+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:32:02.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.408 seconds
[2024-04-30T11:32:32.535+0000] {processor.py:161} INFO - Started process (PID=16980) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:32:32.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:32:32.539+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:32:32.538+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:32:34.806+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:32:34.829+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:32:34.829+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:32:34.851+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:32:34.851+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:32:34.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.348 seconds
[2024-04-30T11:33:05.146+0000] {processor.py:161} INFO - Started process (PID=17026) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:33:05.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:33:05.149+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:33:05.149+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:33:07.432+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:33:07.457+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:33:07.457+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:33:07.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:33:07.477+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:33:07.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.356 seconds
[2024-04-30T11:33:37.719+0000] {processor.py:161} INFO - Started process (PID=17072) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:33:37.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:33:37.722+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:33:37.722+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:33:40.013+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:33:40.034+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:33:40.034+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:33:40.055+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:33:40.055+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:33:40.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.362 seconds
[2024-04-30T11:34:10.314+0000] {processor.py:161} INFO - Started process (PID=17118) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:34:10.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:34:10.318+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:34:10.317+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:34:12.670+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:34:12.694+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:34:12.694+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:34:12.714+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:34:12.714+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:34:12.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.426 seconds
[2024-04-30T11:34:42.944+0000] {processor.py:161} INFO - Started process (PID=17170) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:34:42.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:34:42.948+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:34:42.947+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:34:45.309+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:34:45.331+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:34:45.331+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:34:45.353+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:34:45.353+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:34:45.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.436 seconds
[2024-04-30T11:35:15.576+0000] {processor.py:161} INFO - Started process (PID=17216) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:35:15.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:35:15.579+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:35:15.579+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:35:17.877+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:35:17.902+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:35:17.902+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:35:17.924+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:35:17.923+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:35:17.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.373 seconds
[2024-04-30T11:35:48.376+0000] {processor.py:161} INFO - Started process (PID=17262) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:35:48.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:35:48.380+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:35:48.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:35:50.673+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:35:50.697+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:35:50.696+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:35:50.717+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:35:50.717+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:35:50.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.367 seconds
[2024-04-30T11:36:21.027+0000] {processor.py:161} INFO - Started process (PID=17308) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:36:21.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:36:21.030+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:36:21.030+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:36:23.408+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:36:23.433+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:36:23.432+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:36:23.454+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:36:23.454+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:36:23.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.455 seconds
[2024-04-30T11:36:53.643+0000] {processor.py:161} INFO - Started process (PID=17354) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:36:53.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:36:53.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:36:53.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:36:55.989+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:36:56.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:36:56.012+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:36:56.035+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:36:56.034+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:36:56.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.419 seconds
[2024-04-30T11:37:26.259+0000] {processor.py:161} INFO - Started process (PID=17400) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:37:26.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:37:26.263+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:37:26.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:37:28.592+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:37:28.615+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:37:28.615+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:37:28.635+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:37:28.635+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:37:28.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.402 seconds
[2024-04-30T11:37:58.848+0000] {processor.py:161} INFO - Started process (PID=17446) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:37:58.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:37:58.851+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:37:58.851+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:38:01.255+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:38:01.278+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:38:01.277+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:38:01.299+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:38:01.299+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:38:01.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.477 seconds
[2024-04-30T11:38:31.613+0000] {processor.py:161} INFO - Started process (PID=17492) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:38:31.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:38:31.616+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:38:31.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:38:34.070+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:38:34.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:38:34.091+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:38:34.111+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:38:34.111+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:38:34.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.525 seconds
[2024-04-30T11:39:04.219+0000] {processor.py:161} INFO - Started process (PID=17544) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:39:04.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:39:04.222+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:39:04.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:39:06.570+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:39:06.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:39:06.592+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:39:06.721+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:39:06.721+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:39:06.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.529 seconds
[2024-04-30T11:39:37.106+0000] {processor.py:161} INFO - Started process (PID=17590) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:39:37.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:39:37.110+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:39:37.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:39:39.387+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:39:39.410+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:39:39.409+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:39:39.433+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:39:39.433+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:39:39.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.354 seconds
[2024-04-30T11:40:09.856+0000] {processor.py:161} INFO - Started process (PID=17636) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:40:09.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:40:09.859+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:40:09.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:40:12.184+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:40:12.207+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:40:12.206+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:40:12.226+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:40:12.226+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:40:12.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.396 seconds
[2024-04-30T11:40:42.513+0000] {processor.py:161} INFO - Started process (PID=17688) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:40:42.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:40:42.516+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:40:42.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:40:44.904+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:40:44.928+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:40:44.928+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:40:44.950+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:40:44.950+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:40:44.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.465 seconds
[2024-04-30T11:41:15.181+0000] {processor.py:161} INFO - Started process (PID=17734) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:41:15.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:41:15.185+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:41:15.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:41:17.506+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:41:17.530+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:41:17.529+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:41:17.653+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:41:17.653+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:41:17.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.498 seconds
[2024-04-30T11:41:47.779+0000] {processor.py:161} INFO - Started process (PID=17780) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:41:47.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:41:47.782+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:41:47.782+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:41:50.124+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:41:50.147+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:41:50.147+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:41:50.171+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:41:50.171+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:41:50.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.419 seconds
[2024-04-30T11:42:20.383+0000] {processor.py:161} INFO - Started process (PID=17826) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:42:20.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:42:20.386+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:42:20.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:42:22.682+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:42:22.716+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:42:22.715+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:42:22.740+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:42:22.740+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:42:22.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.385 seconds
[2024-04-30T11:42:53.043+0000] {processor.py:161} INFO - Started process (PID=17872) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:42:53.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:42:53.047+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:42:53.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:42:55.466+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:42:55.490+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:42:55.489+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:42:55.512+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:42:55.512+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:42:55.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.505 seconds
[2024-04-30T11:43:25.916+0000] {processor.py:161} INFO - Started process (PID=17918) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:43:25.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:43:25.920+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:43:25.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:43:28.231+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:43:28.253+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:43:28.253+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:43:28.380+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:43:28.379+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:43:28.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.490 seconds
[2024-04-30T11:43:58.507+0000] {processor.py:161} INFO - Started process (PID=17964) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:43:58.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:43:58.510+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:43:58.509+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:44:00.811+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:44:00.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:44:00.836+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:44:00.856+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:44:00.856+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:44:00.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.375 seconds
[2024-04-30T11:44:31.131+0000] {processor.py:161} INFO - Started process (PID=18010) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:44:31.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:44:31.134+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:44:31.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:44:33.521+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:44:33.543+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:44:33.543+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:44:33.563+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:44:33.562+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:44:33.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.459 seconds
[2024-04-30T11:45:03.757+0000] {processor.py:161} INFO - Started process (PID=18056) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:45:03.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:45:03.761+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:45:03.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:45:06.103+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:45:06.129+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:45:06.129+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:45:06.150+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:45:06.150+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:45:06.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.421 seconds
[2024-04-30T11:45:36.344+0000] {processor.py:161} INFO - Started process (PID=18102) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:45:36.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:45:36.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:45:36.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:45:38.623+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:45:38.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:45:38.645+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:45:38.773+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:45:38.773+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:45:38.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.456 seconds
[2024-04-30T11:46:08.940+0000] {processor.py:161} INFO - Started process (PID=18148) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:46:08.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:46:08.943+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:46:08.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:46:11.254+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:46:11.278+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:46:11.277+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:46:11.298+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:46:11.298+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:46:11.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.384 seconds
[2024-04-30T11:46:41.612+0000] {processor.py:161} INFO - Started process (PID=18200) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:46:41.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:46:41.615+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:46:41.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:46:43.984+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:46:44.006+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:46:44.005+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:46:44.026+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:46:44.026+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:46:44.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.441 seconds
[2024-04-30T11:47:14.273+0000] {processor.py:161} INFO - Started process (PID=18246) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:47:14.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:47:14.277+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:47:14.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:47:16.675+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:47:16.699+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:47:16.698+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:47:16.720+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:47:16.719+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:47:16.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.474 seconds
[2024-04-30T11:47:46.889+0000] {processor.py:161} INFO - Started process (PID=18298) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:47:46.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:47:46.892+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:47:46.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:47:49.188+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:47:49.216+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:47:49.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:47:49.338+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:47:49.338+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:47:49.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.475 seconds
[2024-04-30T11:48:19.474+0000] {processor.py:161} INFO - Started process (PID=18344) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:48:19.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:48:19.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:48:19.477+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:48:21.785+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:48:21.809+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:48:21.808+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:48:21.833+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:48:21.833+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:48:21.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.387 seconds
[2024-04-30T11:48:52.101+0000] {processor.py:161} INFO - Started process (PID=18390) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:48:52.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:48:52.104+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:48:52.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:48:54.444+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:48:54.468+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:48:54.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:48:54.490+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:48:54.490+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:48:54.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.415 seconds
[2024-04-30T11:49:24.717+0000] {processor.py:161} INFO - Started process (PID=18436) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:49:24.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:49:24.720+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:49:24.720+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:49:27.052+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:49:27.075+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:49:27.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:49:27.095+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:49:27.095+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:49:27.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.406 seconds
[2024-04-30T11:49:57.281+0000] {processor.py:161} INFO - Started process (PID=18482) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:49:57.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:49:57.284+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:49:57.284+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:49:59.594+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:49:59.617+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:49:59.617+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:49:59.741+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:49:59.741+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:49:59.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.486 seconds
[2024-04-30T11:50:30.026+0000] {processor.py:161} INFO - Started process (PID=18528) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:50:30.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:50:30.030+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:50:30.030+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:50:32.360+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:50:32.384+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:50:32.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:50:32.406+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:50:32.405+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:50:32.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.405 seconds
[2024-04-30T11:51:02.716+0000] {processor.py:161} INFO - Started process (PID=18574) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:51:02.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:51:02.719+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:51:02.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:51:05.290+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:51:05.325+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:51:05.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:51:05.352+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:51:05.352+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:51:05.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.673 seconds
[2024-04-30T11:51:35.701+0000] {processor.py:161} INFO - Started process (PID=18620) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:51:35.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:51:35.705+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:51:35.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:51:38.141+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:51:38.170+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:51:38.169+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:51:38.192+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:51:38.191+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:51:38.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.520 seconds
[2024-04-30T11:52:08.494+0000] {processor.py:161} INFO - Started process (PID=18666) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:52:08.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:52:08.499+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:52:08.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:52:10.922+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:52:10.946+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:52:10.945+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:52:11.085+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:52:11.084+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:52:11.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.625 seconds
[2024-04-30T11:52:41.218+0000] {processor.py:161} INFO - Started process (PID=18712) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:52:41.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:52:41.222+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:52:41.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:52:43.681+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:52:43.705+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:52:43.705+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:52:43.727+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:52:43.727+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:52:43.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.551 seconds
[2024-04-30T11:53:13.994+0000] {processor.py:161} INFO - Started process (PID=18764) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:53:13.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:53:13.997+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:53:13.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:53:16.601+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:53:16.632+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:53:16.631+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:53:16.659+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:53:16.659+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:53:16.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.693 seconds
[2024-04-30T11:53:46.809+0000] {processor.py:161} INFO - Started process (PID=18810) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:53:46.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:53:46.812+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:53:46.812+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:53:49.192+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:53:49.216+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:53:49.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:53:49.237+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:53:49.236+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:53:49.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.566 seconds
[2024-04-30T11:54:19.589+0000] {processor.py:161} INFO - Started process (PID=18856) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:54:19.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:54:19.592+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:54:19.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:54:21.967+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:54:21.991+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:54:21.990+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:54:22.125+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:54:22.125+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:54:22.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.563 seconds
[2024-04-30T11:54:52.420+0000] {processor.py:161} INFO - Started process (PID=18902) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:54:52.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:54:52.423+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:54:52.423+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:54:54.803+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:54:54.826+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:54:54.826+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:54:54.850+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:54:54.850+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:54:54.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.458 seconds
[2024-04-30T11:55:25.157+0000] {processor.py:161} INFO - Started process (PID=18948) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:55:25.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:55:25.161+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:55:25.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:55:27.821+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:55:27.856+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:55:27.856+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:55:27.878+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:55:27.878+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:55:27.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.751 seconds
[2024-04-30T11:55:58.449+0000] {processor.py:161} INFO - Started process (PID=18994) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:55:58.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:55:58.453+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:55:58.452+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:56:00.988+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:56:01.015+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:56:01.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:56:01.040+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:56:01.040+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:56:01.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.621 seconds
[2024-04-30T11:56:31.413+0000] {processor.py:161} INFO - Started process (PID=19046) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:56:31.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:56:31.417+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:56:31.416+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:56:33.967+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:56:33.996+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:56:33.995+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:56:34.141+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:56:34.141+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:56:34.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.760 seconds
[2024-04-30T11:57:04.439+0000] {processor.py:161} INFO - Started process (PID=19092) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:57:04.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:57:04.443+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:57:04.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:57:07.475+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:57:07.507+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:57:07.506+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:57:07.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:57:07.531+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:57:07.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.126 seconds
[2024-04-30T11:57:37.866+0000] {processor.py:161} INFO - Started process (PID=19138) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:57:37.867+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:57:37.871+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:57:37.870+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:57:40.644+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:57:40.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:57:40.672+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:57:40.697+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:57:40.697+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:57:40.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.863 seconds
[2024-04-30T11:58:11.122+0000] {processor.py:161} INFO - Started process (PID=19184) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:58:11.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:58:11.131+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:58:11.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:58:15.781+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:58:15.827+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:58:15.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:58:15.877+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:58:15.876+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:58:15.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 4.812 seconds
[2024-04-30T11:58:46.516+0000] {processor.py:161} INFO - Started process (PID=19236) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:58:46.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:58:46.522+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:58:46.521+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:58:49.750+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:58:49.776+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:58:49.775+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:58:49.921+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:58:49.920+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:58:49.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 3.436 seconds
[2024-04-30T11:59:20.462+0000] {processor.py:161} INFO - Started process (PID=19282) to work on /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:59:20.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/twitter_data_dag.py for tasks to queue
[2024-04-30T11:59:20.465+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:59:20.465+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:59:23.048+0000] {processor.py:840} INFO - DAG(s) 'tweets_dag_v4' retrieved from /opt/airflow/dags/twitter_data_dag.py
[2024-04-30T11:59:23.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:59:23.072+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T11:59:23.095+0000] {logging_mixin.py:188} INFO - [2024-04-30T11:59:23.094+0000] {dag.py:3954} INFO - Setting next_dagrun for tweets_dag_v4 to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T11:59:23.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/twitter_data_dag.py took 2.660 seconds
